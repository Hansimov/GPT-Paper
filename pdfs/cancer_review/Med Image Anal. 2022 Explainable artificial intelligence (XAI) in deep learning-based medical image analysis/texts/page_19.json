{
    "page": {
        "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_19.png",
        "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_19.png",
        "image_width": 2481,
        "image_height": 3308,
        "regions_num": 2,
        "page_idx": 19
    },
    "regions": [
        {
            "idx": 1,
            "thing": "text",
            "score": 54.5,
            "box": [
                147.7,
                243.2,
                1206.7,
                3089.6
            ],
            "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_19/region_1_text.png",
            "text": "Paul, R., Schabath, M., Gillies, R., Hall, L. Goldgof, D., 2020. Convolutional neural\nnetwork ensembles for accurate lung nodule malignancy prediction 2 years in\nthe future. Comput. Biol. Med. 122, 103882.\n\nPearl, J., 2009. Causality. Cambridge University Press.\n\nPelka, O., Nensa, F,, Friedrich, C.M., 2019. Variations on branding with text occur-\nrence for optimized body parts classification. In: Proceedings of the 2019 41st\nAnnual International Conference of the IEEE Engineering in Medicine and Biol-\nogy Society (EMBC), pp. 890-894.\n\nPeng, T., Boxberg, M., Weichert, W., Navab, N., Marr, C., 2019. Multi-task learn-\ning of a deep K-nearest neighbour network for histopathological image clas-\nsification and retrieval. In: Proceedings of the 22nd International Conference\non Medical Image Computing and Computer-Assisted Intervention MICCAI 2019\ndoi:10.1007/978-3-030-32239-7_75.\n\nPennington, J., Socher, R., Manning, C.D., 2014. Glove: global vectors for word rep-\nresentation. In: Proceedings of the 2014 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pp. 1532-1543.\n\nPerdomo, O., Rios, H., Rodriguez, FJ., Otalora, S. Meriaudeau, F, Miiller, H.,\nGonzalez, F.A., 2019. Classification of diabetes-related retinal diseases using a\ndeep learning approach in optical coherence tomography. Comput. Methods\nPrograms Biomed. 178, 181-189. doi:10.1016/j.cmpb.2019.06.016.\n\nPereira, S., Meier, R., Alves, V., Reyes, M., Silva, C.A., 2018. Automatic brain tumor\ngrading from MRI data using convolutional neural networks and quality assess-\nment. In: Understanding and Interpreting Machine Learning in Medical Image\nComputing Applications. Springer, pp. 106-114.\n\nPesce, E., Joseph Withey, S., Ypsilantis, P.P., Bakewell, R., Goh, V., Montana, G., 2019.\nLearning to detect chest radiographs containing pulmonary lesions using visual\nattention networks. Med. Image Anal. 53, 26-38. doi:10.1016/j.media.2018.12.\n007.\n\nPhilbrick, K.A., Yoshida, K., Inoue, D., Akkus, Z., Kline, T.L., Weston, A.D., Korfiatis, P.,\nTakahashi, N., Erickson, BJ., 2018. What does deep learning see? Insights from\na classifier trained to predict contrast enhancement phase from CT images. Am.\nJ. Roentgenol. 211, 1184-1193. doi:10.2214/AJR.18.20331.\n\nPominova, M., Artemov, A., Sharaev, M., Kondrateva, E., Bernstein, A., Burnaev, E.,\n2018. Voxelwise 3d convolutional and recurrent neural networks for epilepsy\nand depression diagnostics from structural and functional MRI data. In: Pro-\nceedings of the 2018 IEEE International Conference on Data Mining Workshops\n(ICDMW), pp. 299-307.\n\nQi, X., Zhang, L., Chen, Yao, Pi, Y., Chen, Yi, Lv, Q., Yi, Z., 2019. Automated diagnosis\nof breast ultrasonography images using deep neural networks. Med. Image Anal.\n52, 185-198.\n\nQin, R., Wang, Z., Jiang, L., Qiao, K., Hai, J., Chen, J., Xu, J., Shi, D., Yan, B., 2020.\nFine-grained lung cancer classification from PET and CT images based on mul-\ntidimensional attention mechanism. Complexity 2020.\n\nQuellec, G., Lamard, M., Conze, P.H., Massin, P., Cochener, B., 2020. Automatic detec-\ntion of rare pathologies in fundus photographs using few-shot learning. Med.\nImage Anal. 61, 101660.\n\nRadiological Society of North America, 2018. Pneumonia detection challenge.\nhttps://www.rsna.org/education/ai-resources-and-training/ai-image-challenge/\nrsna-pneumonia-detection-challenge-2018\n\nRajaraman, S., Candemir, S., Thoma, G., Antani, S., 2019. Visualizing and explain-\ning deep learning predictions for pneumonia detection in pediatric chest radio-\ngraphs. Med. Imaging 2019. Comput. Aided Diagn., 109500S.\n\nRajpurkar, P., Irvin, J., Ball, R.L, Zhu, K., Yang, B., Mehta, H., Duan, T., Ding, D.,\nBagul, A., Langlotz, C.P., et al., 2018. Deep learning for chest radiograph diag-\nnosis: a retrospective comparison of the CheXNexXt algorithm to practicing ra-\ndiologists. PLoS Med. 15, e1002686.\n\nRajpurkar, P., O’Connell, C., Schechter, A. Asnani, N., Li, J., Kiani, A. Ball, RL,\nMendelson, M., Maartens, G., van Hoving, DJ.others, 2020a. CheXaid: deep\nlearning assistance for physician diagnosis of tuberculosis using chest x-rays in\npatients with HIV. NP] Digit. Med. 3, 1-8.\n\nRajpurkar, P., Park, A., Irvin, J., Chute, C., Bereket, M., Mastrodicasa, D., Langlotz, C.P.,\nLungren, M.P., Ng, A.Y., Patel, B.N., 2020b. AppendiXNet: deep learning for diag-\nnosis of appendicitis from a small dataset of CT exams using video pretraining.\nSci. Rep. 10, 1-7.\n\nReyes, M., Meier, R., Pereira, S., Silva, C.A., Dahlweid, F.M., Tengg-Kobligk, H.V., Sum-\nmers, R.M., Wiest, R., 2020. On the interpretability of artificial intelligence in\nradiology: challenges and opportunities. Radiol. Artif. Intell. 2, e190043.\n\nRezaei, M., Uemura, T., Nappi, J., Yoshida, H., Lippert, C., Meinel, C., 2020. Genera-\ntive synthetic adversarial network for internal bias correction and handling class\nimbalance problem in medical image diagnosis. Medical Imaging 2020. Comput.\nAided Diagn., 113140E.\n\nRibeiro, M.T., Singh, S., Guestrin, C., 2016. Why should i trust you?” Explaining the\npredictions of any classifier. In: Proceedings of the ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining. Association for Comput-\ning Machinery, New York, New York, USA, pp. 1135-1144. doi:10.1145/2939672.\n2939778.\n\nRobnik-Sikonja, M., Kononenko, I., 2008. Explaining classifications for individual\ninstances. IEEE Trans. Knowl. Data Eng. 20, 589-600. doi:10.1109/TKDE.2007.\n190734.\n\nRodin, 1., Fedulova, I., Shelmanov, A., Dylov, D.V, 2019. Multitask and multi-\nmodal neural network model for interpretable analysis of X-ray images. In:\nProceedings of the 019 IEEE International Conference on Bioinformatics and\nBiomedicine (BIBM), pp. 1601-1604.\n\nRonneberger, O., Fischer, P. Brox, T., 2015. U-net: Convolutional networks for\nbiomedical image segmentation. In: Lecture Notes in Computer Science (Includ-\n"
        },
        {
            "idx": 2,
            "thing": "list",
            "score": 60.86,
            "box": [
                1275.4,
                241.1,
                2329.2,
                3111.9
            ],
            "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_19/region_2_list.png",
            "text": "ing Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioin-\nformatics). Springer Verlag, pp. 234-241. doi:10.1007/978-3-319-24574-4_28.\n\nRudin, C., 2019. Stop explaining black box machine learning models for high stakes\ndecisions and use interpretable models instead. Nat. Mach. Intell. 1, 206-215.\ndoi: 10.1038 /s42256-019-0048-x.\n\nSaab, K., Dunnmon, J., Goldman, R., Ratner, A., Sagreiya, H., Ré, C., Rubin, D., 2019.\nDoubly weak supervision of deep learning models for head CT. In: Proceedings\nof the 22nd Int. Medical Image Computing and Computer Assisted Intervention\nMICCAI 2019 doi:10.1007/978-3-030-32248-9_90.\n\nSabour, S., Frosst, N., Hinton, G.E., 2017. Dynamic routing between capsules. Ad-\nvances in neural information processing systems, p. 30.\n\nSarhan, M.H., Eslami, A., Navab, N., Albarqouni, S., 2019. Learning interpretable dis-\nentangled representations using adversarial VAEs. In: Proceedings of the 1st\nMICCAI Domain Adaptation and Representation Transfer and Medical Image\nLearning with Less Labels and Imperfect Data doi:10.1007/978-3-030-33391-1_\n5, 1st Int. Work. Med. Image Learn. with Less Labels Imperfect Data, MIL3ID\n2019, held conjunction with 22nd Int. Conf. Med..\n\nSchlemper, J., Oktay, O., Schaap, M., Heinrich, M., Kainz, B., Glocker, B., Rueckert, D.,\n2019. Attention gated networks: learning to leverage salient regions in medical\nimages. Med. Image Anal. 53, 197-207. doi:10.1016/j.media.2019.01.012.\n\nSchwab, E., Goossen, A., Deshpande, H., Saalbach, A., 2020. Localization of critical\nfindings in chest X-ray without local annotations using multi-instance learning.\nIn: Proceedings of the 17th IEEE International Symposium on Biomedical Imag-\ning, ISBI 2020. IEEE Computer Society, Clinical Informatics, Solutions Services,\nPhilips Research North America, Cambridge, MA, United States, pp. 1879-1882.\ndoi: 10.1109/ISBI45749.2020.9098551.\n\nSedai, S., Mahapatra, D., Ge, Z., Chakravorty, R., Garnavi, R., 2018. Deep multi-\nscale convolutional feature learning for weakly supervised localization of chest\npathologies in x-ray images. In: International Workshop on Machine Learning\nin Medical Imaging. Springer, Cham, pp. 267-275.\n\nSelvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., 2017.\nGrad-cam: Visual explanations from deep networks via gradient-based localiza-\ntion. In: Proceedings of the IEEE international conference on computer vision,\npp. 618-626.\n\nSeo, D., Oh, K., Oh, I.S., 2020. In: Regional Multi-Scale Approach for Visually Pleasing\nExplanations of Deep Neural Networks, 8. IEEE Access, pp. 8572-8582. doi:10.\n1109/ACCESS.2019.2963055.\n\nShahamat, H., Saniee Abadeh, M., 2020. Brain MRI analysis using a deep learning\nbased evolutionary approach. Neural Netw. 126, 218-234. doi:10.1016/j.neunet.\n2020.03.017.\n\nShapira, N., Fokuhl, J., Schulthei&, M., Beck, S., Kopp, E.K., Pfeiffer, D., Dangelmaier, J.,\nPahn, G., Sauter, A.P., Renger, B., et al., 2020. Liver lesion localisation and classifi-\ncation with convolutional neural networks: a comparison between conventional\nand spectral computed tomography. Biomed. Phys. Eng. Express 6, 15038.\n\nShapley, L.S., 2016. A value for n-person games. In: Contributions to the Theory of\nGames (AM-28), Volume II, 17. Princeton University Press, pp. 307-318. doi:10.\n1515/9781400881970-018.\n\nShen, D., Wu, G., Suk, H.I., 2017. Deep learning in medical image analysis. Annu. Rev.\nBiomed. Eng. 19, 221-248. doi:10.1146/annurev-bioeng-071516-044442.\n\nShen, S., Han, S.X., Aberle, D.R., Bui, A.A., Hsu, W., 2019. An interpretable deep hi-\nerarchical semantic convolutional neural network for lung nodule malignancy\nclassification. Expert Syst. Appl. 128, 84-95. doi:10.1016/j.eswa.2019.01.048.\n\nShen, Y., Sheng, B., Fang, R., Li, H., Dai, L., Stolte, S., Qin, J., Jia, W., Shen, D., 2020.\nDomain-invariant interpretable fundus image quality assessment. Med. Image\nAnal. 61. doi:10.1016/j.media.2020.101654.\n\nShinde, S., Chougule, T., Saini, J., Ingalhalikar, M., 2019a. HR-CAM: Precise localiza-\ntion of pathology using multi-level learning in CNNS. In: Proceedings of the\n22nd International Conference on Medical Image Computing and Computer-\nAssisted Intervention ; MICCAI 2019 doi:10.1007/978-3-030-32251-9_33.\n\nShinde, S., Prasad, S., Saboo, Y., Kaushick, R., Saini, J., Pal, P.K., Ingalhalikar, M., 2019b.\nPredictive markers for Parkinson’s disease using deep neural nets on neurome-\nlanin sensitive MRI. Neurolmage Clin. 22, 101748.\n\nSilva-Rodriguez, J., Colomer, A., Sales, M.A., Molina, R., Naranjo, V., 2020. Going\ndeeper through the Gleason scoring scale: an automatic end-to-end system for\nhistology prostate grading and cribriform pattern detection. Comput. Methods\nPrograms Biomed. 195, 105637.\n\nSilva, W., Fernandes, K., Cardoso, M,J., Cardoso, J.S., 2018. Towards complemen-\ntary explanations using deep neural networks. In: Understanding and Inter-\npreting Machine Learning in Medical Image Computing Applications. Springer,\npp. 133-140.\n\nSilva, W., Poellinger, A., Cardoso, J.S., Reyes, M., 2020. Interpretability-guided con-\ntent-based medical image retrieval. In: Proceedings of the International Con-\nference on Medical Image Computing and Computer-Assisted Intervention,\npp. 305-314.\n\nSimonyan, K., Vedaldi, A., Zisserman, A., 2013. Deep inside convolutional networks:\nvisualising image classification models and saliency maps. In: Proceedings of\nthe 2nd International Conference on Learning Representations ICLR 2014 -\nWorkshop Track Proceedings.\n\nSimonyan, K., Zisserman, A., 2014. Very deep convolutional networks for large-scale\nimage recognition. In: Proceedings of the International Conference on Learning\nRepresentations, pp. 1-14.\n\nSingh, S., Karimi, S., Ho-Shon, K., Hamey, L., 2019. From chest X-rays to radiology\nreports: a multimodal machine learning approach. 2019 International Confer-\nence on Digital Image Computing: Techniques and Applications, DICTA 2019. In-\nstitute of Electrical and Electronics Engineers Inc., Department of Computing,\nMacquarie University, Sydney, Australia doi:10.1109/DICTA47822.2019.89458 19.\n"
        }
    ]
}