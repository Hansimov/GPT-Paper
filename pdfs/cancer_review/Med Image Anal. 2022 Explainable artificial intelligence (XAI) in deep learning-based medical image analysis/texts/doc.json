{
    "pdf_filename": "Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis.pdf",
    "pdf_fullpath": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis.pdf",
    "pages_num": 21,
    "pages": [
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_01.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_01.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 17,
                "page_idx": 1
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "title",
                    "score": 99.65,
                    "box": [
                        157.8,
                        693.4,
                        2024.1,
                        833.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_01_title.png",
                    "text": "Explainable artificial intelligence (XAI) in deep learning-based medical\nimage analysis\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 96.02,
                    "box": [
                        155.0,
                        869.8,
                        1804.1,
                        923.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_02_text.png",
                    "text": "Bas H.M. van der Velden*, Hugo J. Kuijf, Kenneth G.A. Gilhuijs, Max A. Viergever\n"
                },
                {
                    "idx": 3,
                    "thing": "text",
                    "score": 89.87,
                    "box": [
                        157.0,
                        950.8,
                        1610.0,
                        983.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_03_text.png",
                    "text": "Image Sciences Institute, University Medical Center Utrecht, Q.02.4.45, P.O. Box 85500, Utrecht, GA 3508, the Netherlands\n"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 98.87,
                    "box": [
                        157.1,
                        1376.1,
                        563.9,
                        1590.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_04_text.png",
                    "text": "Keywords:\n\nExplainable artificial intelligence\nInterpretable deep learning\nMedical image analysis\n\nDeep learning\n\nSurvey\n"
                },
                {
                    "idx": 5,
                    "thing": "title",
                    "score": 98.51,
                    "box": [
                        157.7,
                        1690.2,
                        405.0,
                        1730.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_05_title.png",
                    "text": "1. Introduction\n"
                },
                {
                    "idx": 6,
                    "thing": "title",
                    "score": 87.6,
                    "box": [
                        842.4,
                        1081.2,
                        1115.3,
                        1126.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_06_title.png",
                    "text": "ABSTRACT\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.85,
                    "box": [
                        840.4,
                        1170.6,
                        2325.9,
                        1447.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_07_text.png",
                    "text": "With an increase in deep learning-based methods, the call for explainability of such methods grows, es-\npecially in high-stakes decision making areas such as medical image analysis. This survey presents an\noverview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis.\nA framework of XAI criteria is introduced to classify deep learning-based medical image analysis meth-\nods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according\nto the framework and according to anatomical location. The paper concludes with an outlook of future\nopportunities for XAI in medical image analysis.\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 23.79,
                    "box": [
                        916.0,
                        1491.4,
                        2324.5,
                        1527.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_08_text.png",
                    "text": "This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        157.6,
                        1777.3,
                        1205.6,
                        2297.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_09_text.png",
                    "text": "Deep learning has invoked tremendous progress in automated\nimage analysis. Before that, image analysis was commonly per-\nformed using systems fully designed by human domain experts.\nFor example, such image analysis system could consist of a sta-\ntistical classifier that used handcrafted properties of an image (i.e.,\nfeatures) to perform a certain task. Features included low-level im-\nage properties such as edges or corners, but also higher-level im-\nage properties such as the spiculated border of a cancer. In deep\nlearning, these features are learned by a neural network (in con-\ntrast to being handcrafted) to optimally give a result (or output)\ngiven an input. An example of a deep learning system could be the\noutput ‘cancer’ given the input of an image showing a cancer.\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.8,
                        2300.9,
                        1205.0,
                        2690.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_10_text.png",
                    "text": "Neural networks typically consist of many layers connected via\nmany nonlinear intertwined relations. Even if one is to inspect all\nthese layers and describe their relations, it is unfeasibly to fully\ncomprehend how the neural network came to its decision. There-\nfore, deep learning is often considered a ‘black box’. Concern is\nmounting in various fields of application that these black boxes\nmay be biased in some way, and that such bias goes unnoticed.\nEspecially in medical applications, this can have far-reaching con-\nsequences.\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.88,
                    "box": [
                        153.8,
                        2692.9,
                        1204.7,
                        2776.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_11_text.png",
                    "text": "There has been a call for approaches to better understand the\nblack box. Such approaches are commonly referred to as inter-\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 46.66,
                    "box": [
                        185.0,
                        2889.6,
                        1031.3,
                        2962.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_12_text.png",
                    "text": "* Corresponding author.\nE-mail address: bvelden2@umcutrecht.nl (B.H.M. van der Velden).\n"
                },
                {
                    "idx": 13,
                    "thing": "text",
                    "score": 99.93,
                    "box": [
                        1277.5,
                        1689.8,
                        2325.9,
                        1992.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_13_text.png",
                    "text": "pretable deep learning or explainable artificial intelligence (XAI)\n(Adadi and Berrada, 2018; Murdoch et al., 2019). These terms are\ncommonly interchanged; we will use the term XAI. Some notable\nXAI initiatives include those from the United States Defense Ad-\nvanced Research Projects Agency (DARPA), and the conferences on\nFairness, Accountability, and Transparency by the Association for\nComputing Machinery (ACM FAccT).\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.4,
                        1994.6,
                        2326.0,
                        2341.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_14_text.png",
                    "text": "The stakes of medical decision making are often high. Not sur-\nprisingly, medical experts have voiced their concern about the\nblack box nature of deep learning (Jia et al., 2020), which is the\ncurrent state of the art in medical image analysis (Litjens et al.,\n2017; Meijering, 2020; Shen et al., 2017). Furthermore, regulations\nsuch as the European Union’s General Data Protection Regulation\n(GDPR, Article 15) require the right of patients to receive meaning-\nful information about how a decision was rendered.\n"
                },
                {
                    "idx": 15,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.6,
                        2343.6,
                        2325.6,
                        2690.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_15_text.png",
                    "text": "Researchers in medical imaging are increasingly using XAI to\nexplain the results of their algorithms. Something can be consid-\nered a good explanation if it gives insight into how a neural net-\nwork came to its decision and/or can make the decision under-\nstandable. In this survey, we aim to give a comprehensive overview\nof papers using XAI in medical image analysis. We chose to focus\nsolely on papers that used deep learning-based XAI in medical im-\nage analysis.\n"
                },
                {
                    "idx": 16,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.8,
                        2691.9,
                        2325.4,
                        2950.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_16_text.png",
                    "text": "The search strategy for inclusion of papers was as follows: We\nused the search query “(explainable deep learning OR interpretable\ndeep learning OR XAI OR interpretable machine learning OR ex-\nplainable machine learning) AND (medical imaging OR medical\nimage analysis)” in SCOPUS. We included papers from peer re-\nviewed journals and conferences. We analyzed the query results\n"
                },
                {
                    "idx": 17,
                    "thing": "text",
                    "score": 20.66,
                    "box": [
                        160.0,
                        3073.9,
                        2151.1,
                        3105.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_01/region_17_text.png",
                    "text": "1361-8415/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_02.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_02.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 23,
                "page_idx": 2
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        157.7,
                        234.7,
                        1205.5,
                        756.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_01_text.png",
                    "text": "using the Active learning for Systematic Reviews toolbox (van de\nSchoot et al., 2021). This toolbox uses active learning to sort pa-\npers from most relevant to least relevant, while being updated by\nuser input. Furthermore, we had discussions with colleagues, and\nused a snowballing approach - investigating papers referenced by\nthe included papers and papers that refer to the included papers.\nWe read the title and the abstract of each of these papers, and\nbrowsed paper content if we were not sure whether to include the\npaper. In case of multiple publications by the same authors on the\nSame subject, we chose the journal publication or the most recent\npublication in case of multiple conference publications. Papers up\nto October 2020 are included in the survey.\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        158.0,
                        757.4,
                        1205.3,
                        1889.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_02_text.png",
                    "text": "The survey is structured as follows: We will first introduce the\ntaxonomy of XAI and describe a framework to classify XAI tech-\nniques in Section 2. In Section 3, the discussed papers are charac-\nterized according to this XAI framework. We will discuss applica-\ntions of XAI techniques in medical image analysis. In case of mul-\ntiple papers using the same technique, we will discuss some early\nadopters and summarize the rest of the papers in the tables. Since\nXAI techniques often originate from computer vision, we will elab-\norate on papers that adapted XAI techniques from computer vision\nby adding domain knowledge from the medical imaging field. The\npapers are grouped in the tables according to explanation method\nand according to anatomical location. This survey adds to the re-\nview of Reyes et al. (2020); since they mainly discussed techniques\nin computer vision, without extensively evaluating the adaptation\nof such techniques throughout medical image analysis. Further-\nmore, we describe if and how techniques from computer vision\nhave been adapted specifically for medical image analysis. This sur-\nvey adds to the review of Huff et al. (2021), since they mostly fo-\ncused on examples of visual explanation, while our survey aims\nfor a more holistic approach including non-visual explanation, cri-\ntiques on XAI, and methods for evaluating XAI. Additionally, we\nsystematically survey papers, reflecting the current status of the\nfield of XAI in medical imaging. In Section 4, we discuss the pros\nand cons of the discussed XAI techniques. The survey is concluded\nin Section 5 by discussing the state of the art of XAI in medical\nimage analysis and an outlook of the opportunities of XAI.\n"
                },
                {
                    "idx": 3,
                    "thing": "title",
                    "score": 99.67,
                    "box": [
                        155.6,
                        1935.2,
                        1023.3,
                        1978.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_03_title.png",
                    "text": "2. Explainable artificial intelligence (XAI) framework\n"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.4,
                        2022.6,
                        1204.3,
                        2195.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_04_text.png",
                    "text": "In this section, we will give a brief overview of Explainable Arti-\nficial Intelligence (XAI) techniques found in deep learning for med-\nical image analysis. For exhaustive surveys focused solely on XAI,\nplease refer to Adadi and Berrada (2018) and Murdoch et al. (2019).\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.6,
                        2196.8,
                        1204.5,
                        2500.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_05_text.png",
                    "text": "We will distinguish XAI techniques based on three crite-\nria: model-based versus post hoc, model-specific versus model-\nagnostic, and global versus local (i.e., the scope of the explana-\ntion). The framework of these three criteria is adapted from the\nsurveys of Adadi and Berrada (2018) and Murdoch et al. (2019) and\nis depicted in Fig. 1. The following paragraphs will describe these\ncriteria.\n"
                },
                {
                    "idx": 6,
                    "thing": "title",
                    "score": 99.38,
                    "box": [
                        156.1,
                        2547.0,
                        835.9,
                        2588.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_06_title.png",
                    "text": "2.1. Model-based versus post hoc explanation\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.93,
                    "box": [
                        157.0,
                        2633.4,
                        1202.9,
                        2719.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_07_text.png",
                    "text": "The first distinction we make is model-based explanation ver-\nsus post hoc explanation (Fig. 1).\n"
                },
                {
                    "idx": 8,
                    "thing": "title",
                    "score": 99.44,
                    "box": [
                        156.1,
                        2764.9,
                        614.1,
                        2806.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_08_title.png",
                    "text": "2.1.1. Model-based explanation\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.99,
                    "box": [
                        157.0,
                        2808.4,
                        1205.6,
                        3111.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_09_text.png",
                    "text": "Model-based explanation refers to models, e.g. a linear regres-\nsion model or a support vector machine, that are simple enough\nto be understood, but sophisticated enough to fit a relationship\nbetween input and output well (Murdoch et al., 2019). These are\noften the traditional machine learning models. Examples of model-\nbased explanation enforce the use of a limited amount of features\n(i.e., sparsity), or enforce a human to be able to internally reason\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.5,
                        234.7,
                        2325.8,
                        494.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_10_text.png",
                    "text": "about the model’s entire decision-making process (i.e., simulata-\nbility) (Murdoch et al., 2019). For example, models that enforce\nsparsity such as the least absolute shrinkage and selection operator\n(LASSO, Tibshirani (1996), force many coefficients to zero. Hence, a\nselect subset of features leads to an output, making the inner con-\nstruct of this model explainable.\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.6,
                        496.3,
                        2326.3,
                        887.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_11_text.png",
                    "text": "Since the focus of our survey is on XAI methods for deep\nlearning, model-based explanation by enforcing sparsity or simu-\nlatability is infeasible. Deep learning uses a deep neural network,\ntypically with thousands to millions of weights, which is neither\nsparse, nor suited for a human to internally simulate and reason\nabout the models entire decision making. However, one of the\nmethods mentioned by Murdoch et al. (2019) was model-based\nfeature engineering, i.e., automated approaches for constructing ex-\nplainable features.\n"
                },
                {
                    "idx": 12,
                    "thing": "title",
                    "score": 99.39,
                    "box": [
                        1277.2,
                        940.9,
                        1677.9,
                        983.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_12_title.png",
                    "text": "2.1.2. Post hoc explanation\n"
                },
                {
                    "idx": 13,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.4,
                        984.4,
                        2325.9,
                        1288.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_13_text.png",
                    "text": "Analyzing a trained model (i.e., a neural network in deep learn-\ning) to achieve insight into learned relationships is referred to as\npost hoc explanation. An important distinction between post hoc\nexplanation and model-based explanation is that the former trains\na neural network and subsequently attempts to explain the behav-\nior of the ensuing black box network, whereas the latter forces the\nneural network to be explainable.\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.7,
                        1289.5,
                        2325.5,
                        1549.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_14_text.png",
                    "text": "Methods that provide post hoc explanation include inspection\nof learned features, feature importance, and interaction of features\n(Abbasi-As] and Yu, 2017; Olden et al., 2004; Tsang et al. 2018; as\nwell as visual explanation by saliency maps (Selvaraju et al., 2017;\nSimonyan et al., 2013; Springenberg et al., 2014; Zeiler and Fer-\ngus, 2014; Zhou et al., 2016).\n"
                },
                {
                    "idx": 15,
                    "thing": "title",
                    "score": 99.44,
                    "box": [
                        1277.2,
                        1605.0,
                        2083.1,
                        1646.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_15_title.png",
                    "text": "2.2. Model-specific versus model-agnostic explanation\n"
                },
                {
                    "idx": 16,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.8,
                        1690.1,
                        2325.2,
                        1864.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_16_text.png",
                    "text": "The distinction between model-specific and model-agnostic ex-\nplanation is related to that between model-based and post hoc ex-\nplanation (Adadi and Berrada, 2018), but there are some nuanced\ndifferences.\n"
                },
                {
                    "idx": 17,
                    "thing": "title",
                    "score": 98.93,
                    "box": [
                        1276.2,
                        1917.9,
                        1762.9,
                        1960.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_17_title.png",
                    "text": "2.2.1. Model-specific explanation\n"
                },
                {
                    "idx": 18,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.4,
                        1962.4,
                        2325.6,
                        2222.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_18_text.png",
                    "text": "Model-specific explanation methods are limited to particular\nclasses of models. For example, such a method may use attributes\nthat are specific to a type of neural network. A drawback is that by\naiming at model-specific explanation, we limit our choice of neu-\nral networks, thereby potentially excluding a neural network that\ncould better fit the output to the input data.\n"
                },
                {
                    "idx": 19,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.2,
                        2223.5,
                        2325.6,
                        2483.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_19_text.png",
                    "text": "Model-based explanation is by definition model-specific\n(Adadi and Berrada, 2018), but model-specific explanation is\nnot necessary model-based. Some post hoc saliency mapping\ntechniques are examples of techniques that are specific to a\ncertain class of convolutional neural networks (CNNs), but are not\nmodel-based explanation methods (Murdoch et al., 2019).\n"
                },
                {
                    "idx": 20,
                    "thing": "title",
                    "score": 99.43,
                    "box": [
                        1277.3,
                        2537.7,
                        1783.7,
                        2579.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_20_title.png",
                    "text": "2.2.2. Model-agnostic explanation\n"
                },
                {
                    "idx": 21,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.9,
                        2580.9,
                        2325.3,
                        2842.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_21_text.png",
                    "text": "Model-agnostic explanation is independent of the choice of the\ntype of neural network, operating solely on the input and the out-\nput of the neural network. By perturbing the input, the user can\ninspect what the change is in the output of the neural network.\nThis can therefore explain which regions are driving the output.\nModel-agnostic explanation is naturally post hoc.\n"
                },
                {
                    "idx": 22,
                    "thing": "title",
                    "score": 97.83,
                    "box": [
                        1276.9,
                        2895.8,
                        1655.3,
                        2937.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_22_title.png",
                    "text": "2.3. Scope of explanation\n"
                },
                {
                    "idx": 23,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        1277.0,
                        2982.2,
                        2324.9,
                        3111.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_02/region_23_text.png",
                    "text": "The scope of an explanation distinguishes between explanation\nfor an entire model (global) versus explanation for a single output\n(local).\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_03.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_03.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 14,
                "page_idx": 3
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "figure",
                    "score": 99.8,
                    "box": [
                        404.1,
                        238.8,
                        2077.8,
                        1388.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_01_figure.png"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.92,
                    "box": [
                        156.6,
                        1424.2,
                        2328.9,
                        1494.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_02_text.png",
                    "text": "Fig. 1. The eXplainable Artificial Intelligence (XAI) framework proposed in this paper. A rough overview of XAI techniques (discussed in Section 3) is classified according to\nthis framework. The orange number refers to the section number in the manuscript where the XAI technique is described.\n"
                },
                {
                    "idx": 3,
                    "thing": "title",
                    "score": 99.21,
                    "box": [
                        157.5,
                        1569.9,
                        525.8,
                        1611.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_03_title.png",
                    "text": "2.3.1. Global explanation\n"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        158.2,
                        1611.6,
                        1206.1,
                        2092.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_04_text.png",
                    "text": "Global explanation, also called dataset-level explanation, pro-\nvides general relationships learned by the neural network. For ex-\nample, global explanation could provide feature importance scores\nat the dataset level, i.c., how much do features contribute to the\noutput across the entire dataset (Olden et al., 2004). As an illus-\ntration, one might observe from a neural network that - or even\nhow much - high blood pressure increases the risk of a cardiac\nevent. Another example of global explanation could be visualiza-\ntion of learned filters, i.e., which features are extracted by the neu-\nral network and to what extent are they meaningful to the task at\nhand (Olah et al., 2017; Zeiler and Fergus, 2014).\n"
                },
                {
                    "idx": 5,
                    "thing": "title",
                    "score": 99.21,
                    "box": [
                        155.5,
                        2145.9,
                        512.7,
                        2186.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_05_title.png",
                    "text": "2.3.2. Local explanation\n"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.99,
                    "box": [
                        157.8,
                        2189.2,
                        1205.8,
                        2710.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_06_text.png",
                    "text": "Local explanation provides explanation of a single input. In the\nexample of cardiac risk, an input would be a single person. Local\nexplanation would therefore explain why blood pressure is impor-\ntant to the risk of cardiac event for that single person, whereas\nglobal explanation would describe the relation of blood pressure\nwith risk of cardiac events across the entire dataset. Another ex-\nample of a local explanation could be a saliency map pinpointing\nto a brain tumor on magnetic resonance imaging (MRI) to explain\nwhich part of the MRI mainly contributed to the classifier output\n‘tumor’. Since this explains which part of the image drives the clas-\nsifier to its output ‘tumor’ for that single person, this is a local ex-\nplanation.\n"
                },
                {
                    "idx": 7,
                    "thing": "title",
                    "score": 99.3,
                    "box": [
                        156.1,
                        2764.5,
                        693.6,
                        2807.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_07_title.png",
                    "text": "3. XAI in medical image analysis\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.99,
                    "box": [
                        156.7,
                        2851.1,
                        1205.1,
                        3112.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_08_text.png",
                    "text": "In this section, we will present which XAI techniques are\nused in medical image analysis, and we will discuss adaptations\nof the methods typically seen in computer vision. We catego-\nrize the explanation methods into three types: visual, textual, and\nexample-based; and we will classify each method according to the\nframework of model-based versus post hoc, model-specific ver-\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.5,
                        1568.7,
                        2325.3,
                        1742.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_09_text.png",
                    "text": "sus model-agnostic, and global versus local explanation (Fig. 1).\nTable 1 provides an overview of the most frequently used tech-\nniques and shows their connections according to the taxonomy de-\nfined in Section 2.\n"
                },
                {
                    "idx": 10,
                    "thing": "title",
                    "score": 99.09,
                    "box": [
                        1277.8,
                        1797.0,
                        1616.6,
                        1838.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_10_title.png",
                    "text": "3.1. Visual explanation\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.99,
                    "box": [
                        1278.2,
                        1882.8,
                        2326.2,
                        2231.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_11_text.png",
                    "text": "Visual explanation, also called saliency mapping, is the most\ncommon form of XAI in medical image analysis (Fig. 2). Saliency\nmaps show the important parts of an image for a decision.\nMost saliency mapping techniques use backpropagation-based ap-\nproaches, but some use perturbation-based or multiple instance\nlearning-based approaches. These approaches will be discussed be-\nlow. An overview of papers using saliency maps in medical imag-\ning is shown in Table 2.\n"
                },
                {
                    "idx": 12,
                    "thing": "title",
                    "score": 99.47,
                    "box": [
                        1277.9,
                        2285.6,
                        1884.3,
                        2327.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_12_title.png",
                    "text": "3.1.1. Backpropagation-based approaches\n"
                },
                {
                    "idx": 13,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.2,
                        2327.0,
                        2324.6,
                        2850.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_13_text.png",
                    "text": "(Guided) backpropagation and deconvolution: Some of the ear-\nliest techniques to create saliency maps highlighted pixels that\nhad the highest impact on the analysis output. Examples included\nvisualization of partial derivatives of the output on pixel level\n(Simonyan et al., 2013), deconvolution (Zeiler and Fergus, 2014),\nand guided backpropagation (Springenberg et al., 2014). These\ntechniques provided local, model-specific (only for CNNs), post hoc\nexplanation. These techniques have been used in medical image\nanalysis. For example, de Vos et al. (2019) estimated the amount\nof coronary artery calcium per cardiac or chest computed tomog-\nraphy (CT) image slice, and used deconvolution to visualize from\nwhere in the slice the decision was based on.\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.7,
                        2852.0,
                        2326.2,
                        3111.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_03/region_14_text.png",
                    "text": "Class activation mapping (CAM): Zhou et al. (2016) introduced\nClass Activation Mapping (CAM). They replaced the fully con-\nnected layers at the end of a CNN by global average pooling\non the last convolutional feature maps. The class activation map\nwas a weighted linear sum of presence of visual patterns (cap-\ntured by the filters) at different spatial locations. This technique\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_04.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_04.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 10,
                "page_idx": 4
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "title",
                    "score": 99.3,
                    "box": [
                        156.3,
                        233.2,
                        246.7,
                        268.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_01_title.png",
                    "text": "Table 1\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.79,
                    "box": [
                        156.8,
                        269.5,
                        1679.9,
                        303.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_02_text.png",
                    "text": "Overview of eXplainable AI (XAI) techniques used in medical image analysis, classified by the framework from Section 2.\n"
                },
                {
                    "idx": 3,
                    "thing": "table",
                    "score": 99.78,
                    "box": [
                        156.6,
                        317.7,
                        2322.6,
                        1286.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_03_table.png"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 99.56,
                    "box": [
                        156.1,
                        1301.1,
                        2326.5,
                        1369.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_04_text.png",
                    "text": "* Deep Shapley Additive exPlanations are post hoc and model-specific because of the optimization method, but Shapley Additive exPlanations can also be global and model-\nagnostic.\n"
                },
                {
                    "idx": 5,
                    "thing": "figure",
                    "score": 99.52,
                    "box": [
                        479.8,
                        1414.5,
                        1997.8,
                        2584.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_05_figure.png"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.86,
                    "box": [
                        156.0,
                        2614.2,
                        2327.5,
                        2719.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_06_text.png",
                    "text": "Fig. 2. Number of papers published per year in medical image analysis, for the three types of XAI techniques. Most papers use a visual explanation. The y-axis shows the\nnumber of papers included in this survey, the x-axis shows the year these papers were published in. The dashed line for 2020 is an extrapolation given the situation on\nOctober 31, 2020.\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        156.4,
                        2795.1,
                        1202.1,
                        2881.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_07_text.png",
                    "text": "provided local, model-specific, post hoc explanation. Several re-\nsearchers used this technique in medical imaging (Table 2).\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.5,
                        2882.7,
                        1205.1,
                        3098.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_08_text.png",
                    "text": "CAMs have also been used in medical image analysis in en-\nsembles of CNNs. For example, Jiang et al. (2019) constructed\nan ensemble of Inception-V3, ResNet-152, and Inception-ResNet-\nV2 to distinguish fundus images of healthy subjects or patients\nwith mild diabetic retinopathy from those with moderate or se-\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.7,
                        2794.6,
                        2325.6,
                        3011.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_09_text.png",
                    "text": "vere diabetic retinopathy; and provided a weighted combination\nof the resulting CAMs for localization of diabetic retinopathy.\nLee et al. (2019b) constructed CAMs of the output of an ensem-\nble of four CNNs: VGG-16, ResNet-50, Inception-V3, and Inception-\nResNet-V2, for the detection of acute intracranial hemorrhage.\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1276.8,
                        3013.7,
                        2329.5,
                        3098.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_04/region_10_text.png",
                    "text": "Since medical images often contain information at mul-\ntiple scales, multi-scale CAMs have also been _ proposed.\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_05.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_05.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 3,
                "page_idx": 5
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "title",
                    "score": 98.81,
                    "box": [
                        293.1,
                        303.0,
                        388.0,
                        337.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_05/region_1_title.png",
                    "text": "Table 2\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.91,
                    "box": [
                        293.1,
                        339.1,
                        2191.0,
                        553.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_05/region_2_text.png",
                    "text": "Papers that provide visual explanation. For readability, the papers are sorted on anatomical location and only the first paper dealing with that anatom-\nical location shows the location name. The column ‘Main XAI technique used/based on’ describes which visual explanation technique from Section 3.1\nwas used, or which technique the method in the corresponding paper is based on. When multiple visual explanation techniques have been applied, the\nmost recent technique based on Table 1 has been noted. CAM = class activation mapping, CT = computed tomography, LIME = local interpretable\nmodel-agnostic explanations, LRP = Layer-wise relevance propagation, MRI = magnetic resonance imaging, OCT = optical coherence tomography,\nPET = positron emission tomography, SHAP = Shapley additive explanations.\n"
                },
                {
                    "idx": 3,
                    "thing": "table",
                    "score": 99.8,
                    "box": [
                        295.2,
                        560.0,
                        2197.0,
                        3043.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_05/region_3_table.png"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_06.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_06.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 2,
                "page_idx": 6
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 97.97,
                    "box": [
                        294.0,
                        233.4,
                        535.8,
                        267.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_06/region_1_text.png",
                    "text": "Table 2 (continued)\n"
                },
                {
                    "idx": 2,
                    "thing": "table",
                    "score": 99.69,
                    "box": [
                        297.1,
                        278.0,
                        2410.8,
                        3166.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_06/region_2_table.png"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_07.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_07.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 10,
                "page_idx": 7
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 99.17,
                    "box": [
                        294.1,
                        233.3,
                        535.6,
                        268.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_01_text.png",
                    "text": "Table 2 (continued)\n"
                },
                {
                    "idx": 2,
                    "thing": "table",
                    "score": 99.66,
                    "box": [
                        293.5,
                        279.1,
                        2187.7,
                        1625.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_02_table.png"
                },
                {
                    "idx": 3,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        157.9,
                        1710.3,
                        1205.2,
                        2276.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_03_text.png",
                    "text": "Liao et al. (2019) concatenated feature maps at three scales which\nwere subsequently provided as input for the global average pool-\ning. The provided activation maps showed higher resolution than\nsingle-scale maps, and were better at identifying small structures\non fundus images of the retina. Shinde et al. (2019a) concatenated\nthe feature maps of each layer before max-pooling and also gave\nthose as input to a global average pooling layer. Their ‘High\nResolution’ CAMs provided accurate localizations of brain tumors\non MRI. Garcia-Peraza-Herrera et al. (2020) proposed extracting\nCAMs at multiple resolutions. They showed that the CAMs at high\nresolution were accurate in highlighting interpapillary capillary\nloop patterns in endoscopy images, which were relatively small\ncompared to the entire image.\n"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        157.7,
                        2277.2,
                        1205.4,
                        2927.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_04_text.png",
                    "text": "Gradient-weighted class activation mapping (Grad-CAM):\nSelvaraju et al. (2017) introduced Gradient-weighted Class Ac-\ntivation Mapping (Grad-CAM), which is a generalization of CAM.\nGrad-CAM can work with any type of CNN to produce post hoc\nlocal explanation, whereas CAM specifically needs global aver-\nage pooling. The authors also introduced guided Grad-CAM, an\nelement-wise multiplication between guided backpropagation and\nGrad-CAM. Grad-CAM and Guided Grad-CAM have been used in\nmedical image analysis. For example, Ji (2019) used Grad-CAM to\nshow on which areas of histology lymph node sections a classifier\nbased its decision of metastatic tissue; Kowsari et al. (2020) used\nit to pinpoint small bowel enteropathies on histology; and\nWindisch et al. (2020) used Grad-Cam to show which areas\nof brain MRI made the classifier decide on the presence of a\ntumor.\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.6,
                        2930.4,
                        1204.7,
                        3103.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_05_text.png",
                    "text": "Layer-wise relevance propagation (LRP): Bach et al. (2015) intro-\nduced layer-wise relevance propagation (LRP). LRP uses the out-\nput of the neural network, e.g. a classification score between 0\nand 1, and iteratively backpropagates this throughout the network.\n"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        1278.2,
                        1710.6,
                        2326.2,
                        1883.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_06_text.png",
                    "text": "In each iteration (i.e., each layer), LRP assigns a relevance score\nto each of the input neurons from the previous layers. These dis-\ntributed relevance scores must equal the total relevance score of\nits source neuron, according to the conservation law.\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        1277.6,
                        1885.5,
                        2326.0,
                        2144.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_07_text.png",
                    "text": "LRP has been used in medical image analysis. For example,\nBohle et al. (2019) used LRP for identifying regions responsible\nfor Alzheimer’s disease from brain MR images. They compared the\nsaliency maps provided by LRP with those provided by guided\nbackpropagation, and found that LRP was more specific in iden-\ntifying regions known for Alzheimer’s disease.\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        1277.4,
                        2147.1,
                        2325.6,
                        2492.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_08_text.png",
                    "text": "Deep SHapley Additive exPlanations (Deep SHAP): Lundberg and\nLee (2017) proposed a unified approach for explaining predic-\ntions by using SHapley Additive exPlanations (SHAP). This model-\nagnostic approach used Shapley values (Shapley, 2016), a concept\nfrom game theory. Shapley values determine the marginal contri-\nbution of every feature to the model’s output individually. A down-\nside of Shapley values is that they are resource-intensive to com-\npute, since they require assessment of many permutations.\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.8,
                        2495.5,
                        2325.4,
                        2841.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_09_text.png",
                    "text": "By combining DeepLIFT with Shapley values, Lundberg and\nLee (2017) proposed a fast method to approximate Shapley values\nfor CNNs called Deep SHAP. Deep SHAP has been used in medi-\ncal image analysis. For example, van der Velden et al. (2020) used\na regression CNN to estimate the volumetric breast density from\nbreast MRI. Deep SHAP was used to explain which parts of the im-\nage had a positive contribution and a which parts a negative con-\ntribution to the density estimation.\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.8,
                        2844.4,
                        2326.2,
                        3103.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_07/region_10_text.png",
                    "text": "Trainable attention: While many of the previously mentioned\ntechniques highlighted what regions of the image the net-\nwork focuses on, i.e. to where the attention was directed,\nJetley et al. (2018) proposed a trainable attention mechanism. This\ntrainable attention method highlighted where and in what propor-\ntion the network payed attention to input images for classification,\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_08.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_08.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 23,
                "page_idx": 8
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 99.79,
                    "box": [
                        157.2,
                        234.2,
                        1202.6,
                        320.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_01_text.png",
                    "text": "and used this attention to further amplify relevant areas and sup-\npress irrelevant areas.\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.7,
                        321.7,
                        1205.1,
                        756.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_02_text.png",
                    "text": "In medical imaging, Schlemper et al. (2019) used trainable at-\ntention and introduced grid attention. The rationale behind this\nwas that most objects of interest in medical images are highly\nlocalized. By using grid attention, the trainable attention cap-\ntured the anatomical information in medical images. They demon-\nstrated high performance for both segmentation and localization,\nby adding the attention gates to a UNET (Ronneberger et al., 2015)\nand a variant of VGG (Simonyan and Zisserman, 2014). The atten-\ntion coefficients were used to explain on which areas of the image\nthe network focused.\n"
                },
                {
                    "idx": 3,
                    "thing": "title",
                    "score": 99.55,
                    "box": [
                        156.9,
                        802.9,
                        706.7,
                        844.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_03_title.png",
                    "text": "3.1.2. Perturbation-based approaches\n"
                },
                {
                    "idx": 4,
                    "thing": "title",
                    "score": 99.31,
                    "box": [
                        157.7,
                        889.8,
                        569.4,
                        931.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_04_title.png",
                    "text": "3.1.2.1. Occlusion sensitivity\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.3,
                        932.6,
                        1205.4,
                        1280.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_05_text.png",
                    "text": "Perturbation-based techniques perturb the input image to as-\nsess the importance of certain areas of that image for the task un-\nder consideration. Zeiler and Fergus (2014) used an occlusion sen-\nsitivity analysis to visualize which parts of the image were most\nimportant for classification. For example, they showed that an im-\nage of a dog holding a tennis ball was correctly classified by the\ndog’s breed, except if the face of the dog was occluded, which\nyielded the incorrect classification ‘tennis ball’.\n"
                },
                {
                    "idx": 6,
                    "thing": "title",
                    "score": 99.46,
                    "box": [
                        157.5,
                        1325.6,
                        1097.1,
                        1368.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_06_title.png",
                    "text": "3.1.2.2. Local interpretable model-agnostic explanations (LIME)\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        157.7,
                        1370.0,
                        1206.1,
                        1979.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_07_text.png",
                    "text": "Ribeiro et al. (2016) introduced Local Interpretable Model-\nagnostic Explanations (LIME). LIME provides local explanation by\nreplacing a complex model locally with simpler models, for exam-\nple by approximating a CNN by a linear model. By perturbing the\ninput data, the output of the complex model changes. LIME uses\nthe simpler model to learn the mapping between the perturbed\ninput data and the change in output. The similarity of the per-\nturbed input to the original input is used as a weight, to ensure\nthat explanations provided by the simple models with highly per-\nturbed inputs have less effect on the final explanation. In images,\nRibeiro et al. (2016) implemented the perturbations using super-\npixelsxxxxxxXXxxxx is inclluded in the hyperlink\"?>Achanta et al.,\n2012), rather than individual pixels, to show which regions were\nimportant for explaining a classification.\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        155.9,
                        1980.3,
                        1204.6,
                        2108.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_08_text.png",
                    "text": "LIME has been used by several researchers in medical image\nanalysis. For example, Malhi et al. (2019) used LIME to explain\nwhich areas in gastral endoscopy images contained bloody regions.\n"
                },
                {
                    "idx": 9,
                    "thing": "title",
                    "score": 98.86,
                    "box": [
                        158.7,
                        2155.0,
                        636.9,
                        2196.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_09_title.png",
                    "text": "3.1.2.3. Meaningful perturbation\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.3,
                        2197.9,
                        1205.0,
                        2546.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_10_text.png",
                    "text": "Fong and Vedaldi (2017) introduced meaningful perturbation,\nwhere they perturbed the input image to detect changes in the\npredictions of a trained neural network. Rather than using pertur-\nbations such as occlusion sensitivity that block out parts of the\nimage, they suggested simulating naturalistic or plausible effects,\nleading to more meaningful perturbations, and consequently to\nmore meaningful explanations. They opted for three types of local\nperturbations, namely a constant value, noise, or blurring.\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        157.6,
                        2546.1,
                        1205.3,
                        3113.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_11_text.png",
                    "text": "Uzunova et al. (2019) stated that the perturbations proposed by\nFong and Vedaldi (2017) were not suited for medical images. Re-\nplacing areas of a medical image with a constant value is implau-\nsible, and medical images naturally tend to be noisy and blurry.\nThey proposed to replace pathological regions with a healthy tis-\nSue equivalent using a variational autoencoder (VAE). They showed\nthat the perturbations by the VAE pinpoint pathological regions\nin diverse imaging studies as optical coherence tomography im-\nages of the eye (pathology consisted of intraretinal fluid, subretinal\nfluid, and pigment epithelium detachments), and MRI of the brain\n(pathology consisted of stroke lesions). Furthermore, they showed\nthat using a VAE yielded better localization of pathology compared\nwith using simple blurring or constant-value perturbations.\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.1,
                        235.7,
                        2325.5,
                        581.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_12_text.png",
                    "text": "Lenis et al. (2020) used similar reasoning as\nUzunova et al. (2019), and used inpainting to replace pathological\nregions with healthy tissue equivalents. They showed that the\nperturbations created by inpainting outperformed backpropagation\nand Grad-CAM in pinpointing masses in breast mammography\nand tuberculosis on chest X-rays, based on the Hausdorff distance\nbetween thresholded heatmaps derived from the saliency maps\nand the ground truth labels at pixel level.\n"
                },
                {
                    "idx": 13,
                    "thing": "title",
                    "score": 99.22,
                    "box": [
                        1278.0,
                        638.2,
                        1827.6,
                        680.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_13_title.png",
                    "text": "3.1.2.4. Prediction difference analysis\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1276.2,
                        682.8,
                        2324.6,
                        1204.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_14_text.png",
                    "text": "Zintgraf et al. (2017) adapted prediction difference analysis\n(Robnik-Sikonja and Kononenko, 2008) for generating saliency\nmaps. If each pixel in an image is considered a feature, predic-\ntion difference analysis assigns a relevance value to each pixel, by\nmeasuring how the prediction changes if the pixel is considered\nunknown. Zintgraf et al. (2017) expanded this by adding condi-\ntional sampling, which means that they only analyzed pixels that\nare hard to predict by simply investigating neighboring pixels, and\nby adding multivariable analysis, which means that they analyzed\npatches of connected pixels instead of single pixels. They included\nan analysis of brain MRI of patients with HIV versus healthy con-\ntrols, yielding explanation of the classifier’s decision.\n"
                },
                {
                    "idx": 15,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1276.8,
                        1205.5,
                        2326.0,
                        1509.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_15_text.png",
                    "text": "Seo et al. (2020) used prediction difference analysis in combi-\nnation with superpixels (or supervoxels for 3D) on multiple scales.\nThese multiscale supervoxel-based saliency maps provided expla-\nnations that the authors described as visually pleasing since they\nfollow image edges. The saliency maps explained which regions\nwere informative for a classifier to distinguish between Alzheimer’s\ndisease patients and normal controls.\n"
                },
                {
                    "idx": 16,
                    "thing": "title",
                    "score": 99.21,
                    "box": [
                        1278.4,
                        1565.5,
                        2033.8,
                        1607.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_16_title.png",
                    "text": "3.1.3. Multiple instance learning-based approaches\n"
                },
                {
                    "idx": 17,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.3,
                        1608.5,
                        2325.8,
                        1913.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_17_text.png",
                    "text": "Multiple instance learning can be used for visualizing explana-\ntions. In multiple instance learning, training sets consist of bags\nof instances (Dietterich et al., 1997). These bags are labeled, but\nthe instances are not. In medical image analysis, multiple instance\nlearning can for example be done using a patch-based approach:\nAn image represents the bag, and patches from that image repre-\nsent the instances (Cheplygina et al., 2019).\n"
                },
                {
                    "idx": 18,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.2,
                        1914.0,
                        2324.0,
                        2436.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_18_text.png",
                    "text": "Several researchers have used this approach to pinpoint which\ninstances in the bag are responsible for the classification. For ex-\nample, Schwab et al. (2020) localized critical findings in chest\nX-ray using such a patch-based approach. Each image patch re-\nceived a prediction, and the predictions were overlaid on the im-\nage to visualize on which areas the classifier based its decision.\nAratijo et al. (2020) used multiple instance learning to explain\nwhich areas of a fundus photograph were important for diabetic\nretinopathy. They assessed the severity of the disease using an or-\ndinal scale with grades from 0 to 5. Using a patch-based approach,\nthey provided visual explanation maps for each diabetic retinopa-\nthy grade.\n"
                },
                {
                    "idx": 19,
                    "thing": "title",
                    "score": 98.85,
                    "box": [
                        1279.5,
                        2491.5,
                        1637.1,
                        2533.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_19_title.png",
                    "text": "3.2. Textual explanation\n"
                },
                {
                    "idx": 20,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.9,
                        2577.9,
                        2325.2,
                        2839.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_20_text.png",
                    "text": "Textual explanation is a form of XAI that provides textual de-\nscriptions. Such descriptions include relatively simple characteris-\ntics (e.g. ‘spiculated mass’), up to entire medical reports. We will\ndescribe three types of textual explanation: image captioning, im-\nage captioning with visual explanation, and testing with concept\nattribution.\n"
                },
                {
                    "idx": 21,
                    "thing": "text",
                    "score": 99.86,
                    "box": [
                        1276.9,
                        2840.7,
                        2324.6,
                        2927.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_21_text.png",
                    "text": "An overview of papers using textual explanation in medical\nimaging is shown in Table 3.\n"
                },
                {
                    "idx": 22,
                    "thing": "title",
                    "score": 98.92,
                    "box": [
                        1279.0,
                        2982.7,
                        1624.8,
                        3025.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_22_title.png",
                    "text": "3.2.1. Image captioning\n"
                },
                {
                    "idx": 23,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        1275.9,
                        3027.7,
                        2325.4,
                        3112.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_08/region_23_text.png",
                    "text": "Vinyals et al. (2015) provided textual explanation for images us-\ning an end-to-end image captioning framework. They coupled a\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_09.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_09.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 12,
                "page_idx": 9
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "title",
                    "score": 99.64,
                    "box": [
                        401.7,
                        232.3,
                        496.1,
                        267.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_01_title.png",
                    "text": "Table 3\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        401.0,
                        270.2,
                        2082.8,
                        412.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_02_text.png",
                    "text": "Papers that provide textual explanation. For readability, the papers are sorted on anatomical location and only the first paper deal-\ning with that anatomical location shows the location name. The column ‘Main XAI technique used/based on’ describes which textual\nexplanation technique from Section 3.2 was used, or which technique the method in the corresponding paper is based on. CT = com-\nputed tomography, TCAV = testing with concept activation vectors\n"
                },
                {
                    "idx": 3,
                    "thing": "table",
                    "score": 99.8,
                    "box": [
                        403.3,
                        423.4,
                        2079.4,
                        1574.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_03_table.png"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.5,
                        1657.4,
                        1205.2,
                        2004.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_04_text.png",
                    "text": "convolutional neural network for encoding of the image, with a re-\ncurrent neural network - specifically a long-short term memory\nnet (LSTM) (Hochreiter and Schmidhuber, 1997) - for textual en-\ncoding. They used human-generated sentences as ground truth for\ntraining, and used the bilingual evaluation understudy (BLEU) met-\nric for evaluation. The BLEU-metric describes the precision of word\nN-grams, i.e. a sequence of N words, between generated and refer-\nence sentences (Papineni et al., 2002).\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.5,
                        2007.3,
                        1205.0,
                        2398.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_05_text.png",
                    "text": "Singh et al. (2019) used an image captioning framework to\nprovide textual explanation for chest X-rays. They used word-\nembedding databases Global Vectors (GloVe) (Pennington et al.,\n2014) and the radiology variant RadGloVe (Zhang et al., 2018) to\ntrain the LSTM, and used the aforementioned BLEU metric as well\nas variants METEOR, CIDER, and ROUGE (Banerjee and Lavie, 2005;\nLin, 2004; Vedantam et al., 2015). As expected, higher performance\nwas reached in the generated radiology report when both Rad-\nGloVe and GloVe were used instead of just GloVe.\n"
                },
                {
                    "idx": 6,
                    "thing": "title",
                    "score": 99.33,
                    "box": [
                        157.3,
                        2503.4,
                        873.0,
                        2545.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_06_title.png",
                    "text": "3.2.2. Image captioning with visual explanation\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.3,
                        2546.1,
                        1205.4,
                        2893.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_07_text.png",
                    "text": "Several researchers combined image captioning with visual ex-\nplanation. Zhang et al. (2017a) introduced a framework that used\ndual attention, both for text and for imaging. They used a similar\napproach as with image captioning, i.e. an encoder for the image\nand an LSTM for the text, but added dual attention. This facili-\ntated high-level interactions between image and text predictions,\nand yielded visual attention maps corresponding with textual ex-\nplanation in Histology images.\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        156.6,
                        2895.3,
                        1204.6,
                        3111.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_08_text.png",
                    "text": "Wang et al. 2018 used a similar approach, and showed in their\nchest X-ray example that different parts of the textual explana-\ntion led to different areas of saliency mapping in the image. They\nshowed a saliency map of the chest with multiple regions corre-\nsponding to different radiological findings.\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.6,
                        1658.2,
                        2325.3,
                        1962.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_09_text.png",
                    "text": "Lee et al. (2019a) showed image captioning with visual explana-\ntion for breast mammograms. They added a visual word constraint\nloss to the text-generating LSTM, to ensure that the provided ex-\nplanations follow the correct jargon of breast mammography re-\nports. They showed that adding this loss aids in generating better\ntextual explanation. Furthermore, they linked the radiology reports\nto visual saliency maps.\n"
                },
                {
                    "idx": 10,
                    "thing": "title",
                    "score": 99.35,
                    "box": [
                        1279.3,
                        2023.0,
                        2071.6,
                        2065.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_10_title.png",
                    "text": "3.2.3. Testing with concept activation vectors (TCAV)\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1276.9,
                        2066.2,
                        2324.5,
                        2851.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_11_text.png",
                    "text": "Concept attributions provide explanation corresponding to\nhigh-level concepts that humans find easy to understand\n(Kim et al., 2018). Using Testing with Concept Activation Vectors\n(TCAV), Kim et al. (2018) presented human-friendly linear explana-\ntions of the internal state of neural networks, yielding global ex-\nplanation of the networks in terms of human-understandable con-\ncepts. These concepts can be provided after training of the neu-\nral network as a post hoc analysis. The TCAV algorithm uses user-\ndefined sets of examples of a concept and of random non-concept\nexamples. Such a concept might be ‘stripes’ to assess whether an\nimage contained a zebra, or ‘spiculated mass’ to assess whether\nan image contained a cancer. TCAV quantified the sensitivity of a\ntrained model to such concepts using concept activation vectors\n(CAVs). The response of test cases to these CAVs was then used to\nmeasure the sensitivity to that concept. The authors showed fea-\nsibility of TCAV on a medical image processing example, by re-\nlating physician annotations such as ‘microaneurysm’ to diabetic\nretinopathy in fundus imaging.\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.8,
                        2851.3,
                        2325.3,
                        3111.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_09/region_12_text.png",
                    "text": "Clough et al. (2019) identified cardiac disease in cine-MRI by\nclassifying the latent space of a VAE. They used TCAV to show\nwhich clinically known biomarkers were related to cardiac disease.\nFurthermore, they reconstructed images with low peak ejection\nrate - a characteristic that might be related to cardiac disease -\nby adding the CAV to the latent space.\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_10.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_10.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 19,
                "page_idx": 10
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "title",
                    "score": 99.46,
                    "box": [
                        415.5,
                        232.8,
                        509.1,
                        267.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_01_title.png",
                    "text": "Table 4\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        415.1,
                        269.5,
                        2068.9,
                        411.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_02_text.png",
                    "text": "Papers that provide example-based explanation. For readability, the papers are sorted on anatomical location and only the first\npaper dealing with that anatomical location shows the location name. The column ‘Main XAI technique used/based on’ describes\nwhich example-based explanation technique from Section 3.3 was used, or which technique the method in the corresponding paper\nis based on. CT = computed tomography, MRI = magnetic resonance imaging.\n"
                },
                {
                    "idx": 3,
                    "thing": "table",
                    "score": 99.66,
                    "box": [
                        415.7,
                        424.5,
                        2063.8,
                        1038.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_03_table.png"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        158.1,
                        1122.8,
                        1205.2,
                        1645.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_04_text.png",
                    "text": "Graziani et al. (2020) expanded on TCAV by introducing regres-\nsion concept vectors. The main addition was that, while TCAV indi-\ncated the presence or absence of binary concepts, regression con-\ncept vectors indicated continuous-valued measures of a concept.\nThis can be useful when investigating a continuous concept such\nas tumor size. Graziani et al. (2020) showed that by using regres-\nsion concept vectors, they could for example explain why the net-\nwork classified one area of a breast histopathology image as cancer\nand another as healthy: Both areas of the image scored high on the\nconcept ‘contrast’, but the concept ‘nuclei area’, referring to a clin-\nically used system for evaluating cell size, was different between\nhealthy and cancerous regions.\n"
                },
                {
                    "idx": 5,
                    "thing": "title",
                    "score": 99.52,
                    "box": [
                        157.5,
                        1684.8,
                        736.8,
                        1726.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_05_title.png",
                    "text": "3.2.4. Other tel explanation techniques\n"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.8,
                        1727.4,
                        1205.3,
                        2120.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_06_text.png",
                    "text": "Shen et al. (2019) used what they called a hierarchical seman-\ntic CNN to predict malignancy of lung nodules on CT. They clas-\nsified five textual descriptions of image characteristics represen-\ntative of lung nodule malignancy that are typically assessed by a\nradiologist. The task of finding textual descriptions was combined\nwith the main task of classifying lung nodule malignancy. Although\ntheir hierarchical semantic CNN did not significantly outperform a\nnormal CNN in predicting nodule malignancy, the method did pro-\nvide human-interpretable characteristics of the nodules.\n"
                },
                {
                    "idx": 7,
                    "thing": "title",
                    "score": 99.55,
                    "box": [
                        155.7,
                        2159.4,
                        631.9,
                        2201.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_07_title.png",
                    "text": "3.3. Example-based explanation\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.3,
                        2246.0,
                        1205.0,
                        2593.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_08_text.png",
                    "text": "Example-based explanation is an XAI technique that provides\nexamples relating to the data point that is currently being ana-\nlyzed. This can be useful when trying to explain why a neural net-\nwork came to a decision, and is related to how humans reason. For\nexample, when a pathologist examines a biopsy of a patient that\nshows similarity with an earlier patient examined by the patholo-\ngist, the clinical decision may be enhanced by knowing the assess-\nment of that earlier biopsy.\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        155.8,
                        2595.1,
                        1205.4,
                        2768.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_09_text.png",
                    "text": "Example-based explanation often optimizes the hidden layers\ndeep in the neural network (i.e., the latent space) in such a way\nthat similar points are close to each other in this latent space,\nwhile dissimilar points are further away in the latent space.\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.92,
                    "box": [
                        155.8,
                        2769.8,
                        1204.8,
                        2856.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_10_text.png",
                    "text": "An overview of papers using example-based explanation in\nmedical imaging is shown in Table 4.\n"
                },
                {
                    "idx": 11,
                    "thing": "title",
                    "score": 99.1,
                    "box": [
                        156.3,
                        2895.7,
                        475.4,
                        2937.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_11_title.png",
                    "text": "3.3.1. Triplet network\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.5,
                        2938.7,
                        1205.3,
                        3111.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_12_text.png",
                    "text": "Several papers provided example-based explanation using a\ntriplet network (Hoffer and Ailon, 2015). A triplet network consists\nof three identical networks with shared parameters. By feeding\nthese networks three input samples, the network calculates two\n"
                },
                {
                    "idx": 13,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.6,
                        1122.6,
                        2325.4,
                        1470.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_13_text.png",
                    "text": "values consisting of the Lz distances between the representations\nin the latent space (i.e., embedded representations) of these input\nsamples. This allows learning of useful representations by unsu-\npervised comparison of samples. When analyzing a data point, in-\nspection of neighbors in this embedded representation will provide\nexamples of data points that are similar to the data point that is\nbeing analyzed, which can provide explanation why the network\ncame to its output.\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        1277.7,
                        1471.1,
                        2326.2,
                        1774.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_14_text.png",
                    "text": "Peng et al. (2019) used example-based explanation in colorectal\ncancer histology. They first trained a CNN using a triplet loss, hash-\ning, and k hard-negatives to learn an embedding that preserves\nsimilarity. In testing, a coarse-to-fine search yielded the 10 near-\nest examples from a testing database related to the input image.\nThis provided explanation on which images similar to the image\nthat was being analyzed the network based a decision.\n"
                },
                {
                    "idx": 15,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.3,
                        1777.9,
                        2325.8,
                        2167.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_15_text.png",
                    "text": "Yan et al. (2018) utilized a radiological picture archiving and\ncommunication systems (PACS) to extract 32000 clinically relevant\nlesions from the entire body. To learn relevant lesion embeddings,\nthey trained a triplet network with three supervision cues: lesion\nsize, lesion anatomical location (e.g. lung, liver, or kidney), and\nrelative coordinate of the lesion in the body. These embeddings\nshowed good separation based on anatomical location (e.g., liver\nlesions were separated from lung lesions), and could accurately re-\ntrieve example-based explanation from a test set.\n"
                },
                {
                    "idx": 16,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.5,
                        2169.2,
                        2325.4,
                        2517.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_16_text.png",
                    "text": "Codella et al. (2018) also used a triplet loss but combined it\nwith global average pooling, the technique used in CAM. Con-\nsequently, they could not only extract example-based explana-\ntion, but they also provided query activation maps and search re-\nsult activation maps. In other words, a visual explanation showed\nwhich region of the input image the network used to generate the\nexample-based explanation. They demonstrated this technique in\ndermatology images of melanoma.\n"
                },
                {
                    "idx": 17,
                    "thing": "title",
                    "score": 99.14,
                    "box": [
                        1278.5,
                        2590.5,
                        1654.0,
                        2632.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_17_title.png",
                    "text": "3.3.2. Influence functions\n"
                },
                {
                    "idx": 18,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.2,
                        2633.7,
                        2325.7,
                        3024.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_18_text.png",
                    "text": "Wei Koh and Liang (2017) proposed to use influence functions\nto explain on which inputs from a training set a decision was\nbased. They did so by investigating what would happen in case\nan input from the training set would not be available or would\nbe changed. Since it is expensive to assess this by perturbation,\nthey provided an efficient approximation using influence functions\n(Cook and Weisberg, 1980). This implementation of influence func-\ntions is related to SHAP in the sense that they both allow efficient\ncomputation of feature importance.\n"
                },
                {
                    "idx": 19,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1275.3,
                        3027.0,
                        2325.7,
                        3111.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_10/region_19_text.png",
                    "text": "Wang et al. (2019) used influence functions to explain which\nclassifications of liver lesions on multiphase MRI were associ-\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_11.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_11.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 19,
                "page_idx": 11
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.6,
                        233.8,
                        1204.6,
                        539.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_01_text.png",
                    "text": "ated with which radiological characteristics. This global explana-\ntion provided insight into the neural network’s behavior. For ex-\nample, the class ‘benign cyst’ was most often associated with the\nradiological finding ‘thin-walled mass’. Since the network did not\nonly output the class label but also the corresponding radiologi-\ncal characteristics, this explanation could enhance user trust in the\noutput of the network.\n"
                },
                {
                    "idx": 2,
                    "thing": "title",
                    "score": 98.92,
                    "box": [
                        156.9,
                        606.7,
                        405.0,
                        648.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_02_title.png",
                    "text": "3.3.3. Prototypes\n"
                },
                {
                    "idx": 3,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        157.7,
                        649.4,
                        1205.5,
                        1258.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_03_text.png",
                    "text": "Chen et al. 2019 proposed to use typical examples as expla-\nnation (i.e., prototypes), which they described as ‘this-looks-like-\nthat’. The method reflected case-based reasoning that humans per-\nform. For example, when a person explains why a picture contains\na car, they can internally reason that this is a car because it looks\nlike a car they have seen before. A prototype layer was added to\nthe neural network, which grouped training inputs according to\ntheir classes in the latent space. A prototype was picked for each\nclass, consisting of a typical example of that class. During testing,\nthe method utilized parts of the test image that resembled these\ntrained prototypes. The output was a weighted combination of the\nsimilarities to these prototypes. Hence, the explanation was an ac-\ntual computation of the neural network, not a post hoc approxi-\nmation.\n"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        156.1,
                        1260.6,
                        1204.5,
                        1519.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_04_text.png",
                    "text": "Uehara et al. (2019) used prototypes to explain why a neural\nnetwork classified patches of histology images as cancer or as not-\ncancer. The network was able to identify on which parts of the im-\nage it based its decision, and to what extent these parts of the im-\nage were similar to prototypical examples learned from the train-\ning set.\n"
                },
                {
                    "idx": 5,
                    "thing": "title",
                    "score": 99.42,
                    "box": [
                        156.5,
                        1587.4,
                        721.9,
                        1629.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_05_title.png",
                    "text": "3.3.4. Examples from the latent space\n"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.3,
                        1631.1,
                        1205.2,
                        2022.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_06_text.png",
                    "text": "Sarhan et al. (2019) proposed learning disentangled represen-\ntations of the latent space using a residual adversarial VAE with\na total correlation constraint. This adversarial VAE enhanced the\nfidelity of the reconstruction and provided more detailed descrip-\ntions of underlying generative characteristics of the data. When an-\nalyzing reconstructions by traversing through the latent space, they\nshowed that their method yielded reconstructions that were more\ntrue to human-interpretable concepts such as lesion size, lesion ec-\ncentricity, and skin color compared with a regular VAE.\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        157.6,
                        2023.3,
                        1205.8,
                        2588.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_07_text.png",
                    "text": "Biffi et al. (2020) provided a framework for explainable anatom-\nical shape analysis using a ladder VAE (Sgnderby et al., 2016). They\ncoupled this ladder VAE with a multi-layered perceptron, enabling\nthe network to train end-to-end for classification tasks. By doing\nthis, the highest level of the latent space was enforced to be low-\ndimensional (2D or 3D), which meant that these learned latent\nspaces could be directly visualized without the need of further di-\nmensionality reduction after training. They provided dataset-level\nexplanation using these low-dimensional latent spaces to visual-\nize differences in shape for hypertrophic cardiomyopathy versus\nhealthy controls on cardiac MRI, and for Alzheimer’s disease ver-\nsus healthy controls on brain MRI by visualizing the shape of the\nhippocampus.\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        157.8,
                        2589.4,
                        1205.6,
                        3112.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_08_text.png",
                    "text": "Silva et al. (2018) proposed example-based explanation that\nshowed similar and dissimilar cases foraesthetic results of breast\nsurgery on photos, and for skin images on dermoscopy. They iden-\ntified these examples using a nearest neighbor search in latent\nSpace: The nearest neighbor of the same class was considered the\nmost similar case, and the nearest neighbor of the other class\nwas considered the most dissimilar case. Their explanation also in-\ncluded rule extraction from meta-features (e.g. the color of a skin\nlesion or the visibility of scars). They proposed three criteria to\nmeasure the validity of the rule-extracted explanation, namely: (1)\ncompleteness, i.e. the explanation should be general enough to be\napplied to more than one observation; (2) correctness, i.e. if the\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        1277.0,
                        234.5,
                        2325.5,
                        363.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_09_text.png",
                    "text": "explanation itself was considered a model, it should correctly iden-\ntify which class it belongs to; and (3) compactness, i.e. the expla-\nnation should be succinct.\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.93,
                    "box": [
                        1277.6,
                        364.5,
                        2325.8,
                        756.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_10_text.png",
                    "text": "In later work, Silva et al. (2020) combined example-based ex-\nplanation with saliency mapping. First, they trained a baseline CNN\nto classify chest X-rays into pleural effusion versus non-pleural ef-\nfusion. After that, the CNN was fine-tuned on saliency maps. In\ntesting, a nearest neighbor search between the latent space of the\ntest image and a curated ‘catalogue’ set of images was performed.\nAdding the saliency map yielded more consistent examples than\nextracting examples without the saliency map (i.e., the baseline\nCNN).\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.1,
                        756.5,
                        2324.5,
                        1365.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_11_text.png",
                    "text": "Sabour et al. (2017) showed that by replacing the scalar feature\nmaps from convolution neural networks by vectorized representa-\ntions (i.e., capsules), they were able to encode high-level features\nof images. Capsules were basically subcollections of neurons in a\nlayer. These were linked to subcollections of neurons in subsequent\nlayers, forming a capsule network. This capsule network was opti-\nmized using dynamic routing. In short, higher level capsules were\nactivated if their corresponding lower-level capsules are active.\nThis correspondence was described by routing coefficients, which\nsummed to one for each capsule. The coefficients were iteratively\n(i.e., dynamically) updated when the capsule network received new\ninput data. For the MNIST digits dataset, Sabour et al. (2017) found\nthat these capsules learn human-interpretable features such as\nscale, thickness, and skew.\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.6,
                        1367.2,
                        2326.1,
                        1802.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_12_text.png",
                    "text": "LaLonde et al. (2020) used capsules for lung cancer diagnosis,\nwhile also predicting visual attributes such as sphericity, lobula-\ntion, and texture. Since these visual attributes were not necessar-\nily mutually exclusive, as was the case in MNIST (a digit cannot\nbe a two and a nine at the same time), they adapted the dy-\nnamic routing algorithm accordingly. Specifically, the routing co-\nefficients did not have to sum to one in their implementation.\nLaLonde et al. (2020) showed that their implementation was in-\ndeed able to predict these visual attributes as well as lung nodule\nmalignancy.\n"
                },
                {
                    "idx": 13,
                    "thing": "title",
                    "score": 99.57,
                    "box": [
                        1276.6,
                        1847.9,
                        1856.1,
                        1890.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_13_title.png",
                    "text": "4. Pros and cons of XAI techniques\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.6,
                        1934.3,
                        2326.2,
                        2196.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_14_text.png",
                    "text": "All XAI techniques described in Section 3 have pros and cons,\ninfluencing how one would choose from the various options. We\nwill structure these pros and cons in the categories ease of use,\nvalidity, robustness, computational cost, necessity to fine-tune, and\nopen-source availability. An overview of these pros and cons per\nmethod from Table 1 is given in Table 5.\n"
                },
                {
                    "idx": 15,
                    "thing": "title",
                    "score": 98.47,
                    "box": [
                        1277.9,
                        2241.8,
                        1508.2,
                        2283.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_15_title.png",
                    "text": "4.1. Ease of use\n"
                },
                {
                    "idx": 16,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1278.0,
                        2327.4,
                        2325.7,
                        2675.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_16_text.png",
                    "text": "We define the ease of use by the potential of XAI tech-\nniques to be ‘plug-and-play’. Post hoc model agnostic techniques\nhave the highest ease of use. These methods generally consist of\nperturbation-based visual explanation techniques such as occlusion\nsensitivity. These techniques can be used on any trained neural\nnetwork to provide a visual explanation. Model-based techniques\ntypically have lowest ease of use, since the explanation is embed-\nded in the design of the neural network.\n"
                },
                {
                    "idx": 17,
                    "thing": "title",
                    "score": 98.25,
                    "box": [
                        1278.2,
                        2720.8,
                        1457.6,
                        2762.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_17_title.png",
                    "text": "4.2. Validity\n"
                },
                {
                    "idx": 18,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.8,
                        2807.7,
                        2325.1,
                        3025.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_18_text.png",
                    "text": "We define validity by whether the explanation is correct and\ncorresponds to what the end-user expects. In case of visual ex-\nplanation, this can be assessed for example by asking a radiolo-\ngist whether the explanation points towards the pathology that the\nneural network was designed to classify.\n"
                },
                {
                    "idx": 19,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        1277.5,
                        3027.0,
                        2325.4,
                        3111.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_11/region_19_text.png",
                    "text": "Research on quantifying validity of XAI is sparse, and currently\nfocuses on visual explanation. Arun et al. (2021) aimed to quan-\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_12.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_12.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 13,
                "page_idx": 12
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "title",
                    "score": 99.46,
                    "box": [
                        156.3,
                        232.6,
                        249.5,
                        268.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_01_title.png",
                    "text": "Table 5\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.85,
                    "box": [
                        157.7,
                        268.7,
                        2129.3,
                        303.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_02_text.png",
                    "text": "Pros and cons of XAI techniques. Pros are depicted by +, cons by -. The letters in the column Open source (original paper) refer to the URL below the table.\n"
                },
                {
                    "idx": 3,
                    "thing": "table",
                    "score": 99.75,
                    "box": [
                        154.6,
                        317.6,
                        2323.8,
                        1359.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_03_table.png"
                },
                {
                    "idx": 4,
                    "thing": "text",
                    "score": 97.09,
                    "box": [
                        157.5,
                        1369.7,
                        998.2,
                        1869.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_04_text.png",
                    "text": "n.t. = not tested by studies on that criterion.\n\ninc. = inconclusive results between studies on that criterion.\na https://github.com/zhoubolei/CAM\n\nb https://github.com/Cloud-CV/Grad-CAM\n\nc https://github.com/slundberg/shap\n\nd https://github.com/saumya-jetley/cd_ICLR18_LearnToPayAttention\ne https://github.com/marcotcr/lime\n\nf https://github.com/ruthcfong/perturb_explanations\n\ng https://github.com/Imzintgraf/DeepVis-PredDiff\n\nh https://github.com/zizhaozhang/tandemnet\n\ni https://github.com/tensorflow/tcav\n\nj https://github.com/eladhoffer/TripletNet\n\nk https: //github.com/kohpangwei/influence-release\n\n| https://github.com/cfchen-duke/ProtoPNet\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        157.2,
                        1978.1,
                        1205.3,
                        2457.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_05_text.png",
                    "text": "tify the validity of visual explanation techniques using the SIIM-\nACR Pneumothorax Segmentation and RSNA Pneumonia Detection\ndatabases (Society for Imaging Informatics in Medicine and Ameri-\ncan College of Radiology, 2019; Radiological Society of North Amer-\nica, 2018). They compared four of the methods discussed in this\npaper: backpropagation, guided backpropagation, Grad-CAM, and\nguided Grad-CAM. Of these methods, Grad-CAM showed the high-\nest validity. Note that this study solely focuses on chest X-rays.\nTherefore, more research is needed to investigate the validity of\nvisual explanation techniques in other modalities and anatomical\nlocations.\n"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.6,
                        2457.5,
                        1204.8,
                        2849.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_06_text.png",
                    "text": "In case of textual explanation, validity can be assessed by com-\nparing the generated textual explanation to the ground truth text.\nIn case of example-based explanation, validity can be assessed\nby comparing relevant characteristics of found examples, such as\npatient or clinicopathological characteristics. To the best of our\nknowledge, there have not been such rigorous studies on validity\nperformed for textual explanation and for example-based variation\nas there are for visual explanation (Arun et al., 2021). Hence, more\nresearch in this area is desired.\n"
                },
                {
                    "idx": 7,
                    "thing": "title",
                    "score": 98.3,
                    "box": [
                        156.4,
                        2895.6,
                        387.3,
                        2937.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_07_title.png",
                    "text": "4,3. Robustness\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        157.2,
                        2981.4,
                        1202.8,
                        3112.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_08_text.png",
                    "text": "The robustness of XAI techniques can be assessed by intention-\nally changing certain aspects of the deep learning framework and\nmeasuring the effect of these changes to the given explanation.\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        1276.9,
                        1979.5,
                        2324.9,
                        2107.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_09_text.png",
                    "text": "The robustness is mainly quantified for visual explanation tech-\nniques, using parameter randomization tests and data randomiza-\ntion tests.\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.7,
                        2108.7,
                        2325.9,
                        2413.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_10_text.png",
                    "text": "The parameter randomization test compares visual explanation\nfrom a trained CNN with visual explanation from a randomly ini-\ntialized untrained CNN of the same architecture. If the explanation\ndepends on the learned parameters of the CNN (the desired situ-\nation), the two explanations should differ substantially. If the two\nexplanations are similar, the visual explanation technique is insen-\nsitive to the properties of the CNN.\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1277.8,
                        2413.3,
                        2325.9,
                        2718.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_11_text.png",
                    "text": "The data randomization test compares visual explanation from\na trained CNN with visual explanation from a CNN trained on the\nsame dataset but with randomly imputed labels. If the explana-\ntion depends on the data labels (the desired situation), the two\nexplanations should differ substantially. If the two explanations are\nsimilar, the visual explanation does not depend on the relationship\nbetween images and labels.\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        1277.4,
                        2719.5,
                        2325.3,
                        3022.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_12_text.png",
                    "text": "Adebayo et al. (2018) performed these two tests for many vi-\nsual explanation methods including backpropagation, guided back-\npropagation, Grad-CAM, and guided Grad-CAM. They showed that\nguided backpropagation and guided Grad-CAM provided a similar\nvisual explanation in both tests, and might be emphasizing edges.\nHence, caution is advised when using such methods for visualiza-\ntion.\n"
                },
                {
                    "idx": 13,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1276.6,
                        3025.7,
                        2325.8,
                        3110.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_12/region_13_text.png",
                    "text": "Eitel and Ritter (2019) evaluated the robustness of visual ex-\nplanation techniques guided backpropagation, layer-wise relevance\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_13.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_13.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 27,
                "page_idx": 13
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 99.91,
                    "box": [
                        156.5,
                        233.3,
                        1204.6,
                        493.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_01_text.png",
                    "text": "propagation, and occlusion sensitivity in medical images over mul-\ntiple training runs, specifically for the classification of Alzheimer’s\ndisease using brain MRI. They found that layer-wise relevance\npropagation and guided backpropagation produced the most coher-\nent visual explanation. This was not fully in line with the results\nof Adebayo et al. (2018).\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.83,
                    "box": [
                        155.7,
                        495.6,
                        1203.8,
                        624.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_02_text.png",
                    "text": "Arun et al. (2021) performed similar analyses. Their results\nshowed that guided backpropagation and Grad-CAM passed the\nparameter randomization test.\n"
                },
                {
                    "idx": 3,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        157.0,
                        626.5,
                        1204.6,
                        799.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_03_text.png",
                    "text": "These conflicting results demonstrate that more research is de-\nsired for visual explanation techniques in medical image analy-\nsis. For textual and example-based XAI, such rigorous comparison\nstudies have not yet been performed.\n"
                },
                {
                    "idx": 4,
                    "thing": "title",
                    "score": 99.02,
                    "box": [
                        156.2,
                        845.5,
                        514.3,
                        887.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_04_title.png",
                    "text": "4.4. Computational cost\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.86,
                    "box": [
                        157.7,
                        931.4,
                        1205.3,
                        1018.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_05_text.png",
                    "text": "Computational cost of XAI is seldom reported in papers, but can\nbe assessed by comparing how these explanation techniques work.\n"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.87,
                    "box": [
                        156.4,
                        1018.8,
                        1204.4,
                        1149.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_06_text.png",
                    "text": "Since model-based techniques embed the explanation in the\ndesign of the neural network, it is obvious that these explanations\nare relatively costly to produce.\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        157.6,
                        1150.1,
                        1205.7,
                        1628.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_07_text.png",
                    "text": "For visual explanation techniques, there is a clear dis-\ntinction between’ backpropagation-based and __perturbation-\nbased techniques with respect to their computational needs.\nBackpropagation-based techniques typically make a_ single\npass back through the neural network, which is relatively fast.\nPerturbation-based techniques require, however, extensive per-\nturbation of input images to measure the influence of these\nperturbations on the output. Therefore, these techniques are\ngenerally more computationally-expensive. This can especially be\nthe case in 3-dimensional, 4-dimensional, and/or multi-modality\nimages, which often occur in medical image analysis.\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        156.5,
                        1629.6,
                        1203.9,
                        1801.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_08_text.png",
                    "text": "The computational costs of the post hoc textual explanation\nTCAV and the post hoc example-based explanation of influence\nfunctions in medical image analysis has not rigorously been re-\nported.\n"
                },
                {
                    "idx": 9,
                    "thing": "title",
                    "score": 99.24,
                    "box": [
                        156.6,
                        1847.3,
                        578.0,
                        1890.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_09_title.png",
                    "text": "4.5. Necessity of fine-tuning\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        157.0,
                        1935.4,
                        1203.8,
                        2064.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_10_text.png",
                    "text": "Some explanation techniques require no fine-tuning of parame-\nters while others require fine-tuning of parameters associated with\nthe XAI technique.\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        155.9,
                        2066.1,
                        1204.5,
                        2195.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_11_text.png",
                    "text": "Since model-based techniques embed the explanation in the\ndesign of the neural network, it is obvious that fine-tuning of the\nnetwork will influence the explanation.\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        156.3,
                        2196.8,
                        1205.5,
                        2413.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_12_text.png",
                    "text": "For visual explanation, most backpropagation techniques have a\nlimited number of parameters to tune. For example, in Grad-CAM,\nthe user needs to choose at which layer to inspect the activation\nand in Deep SHAP, one needs to choose samples from the training\nset to calculate a background signal.\n"
                },
                {
                    "idx": 13,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        156.9,
                        2414.9,
                        1205.3,
                        2631.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_13_text.png",
                    "text": "Perturbation-based visual explanation techniques often require\na choice of the perturbation. For example, both occlusion sensitiv-\nity and LIME require the user to define the size and shape of the\noccluded areas. In meaningful perturbation, the user has to define\nwhat kind of perturbation technique is deemed best.\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.6,
                        2631.5,
                        1204.7,
                        2849.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_14_text.png",
                    "text": "The post hoc textual explanation TCAV requires some fine-\ntuning with respect to the concepts that will be tested. The post\nhoc example-based explanation technique of influence functions\nrequires definition of the functions of which the influence is to be\nmeasured.\n"
                },
                {
                    "idx": 15,
                    "thing": "title",
                    "score": 98.51,
                    "box": [
                        156.2,
                        2895.2,
                        585.0,
                        2937.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_15_title.png",
                    "text": "4.6. Open-source availability\n"
                },
                {
                    "idx": 16,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.9,
                        2981.2,
                        1205.7,
                        3111.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_16_text.png",
                    "text": "Most XAI techniques are available from open source. Often,\ncode is available from the authors of the original paper. Many tech-\nniques are also implemented in XAI packages such as captum.ai. An\n"
                },
                {
                    "idx": 17,
                    "thing": "text",
                    "score": 99.66,
                    "box": [
                        1277.3,
                        233.5,
                        2326.2,
                        319.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_17_text.png",
                    "text": "overview of open-source availability of XAI techniques is given in\nTable 5.\n"
                },
                {
                    "idx": 18,
                    "thing": "title",
                    "score": 98.4,
                    "box": [
                        1277.7,
                        364.3,
                        1493.9,
                        407.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_18_title.png",
                    "text": "5. Discussion\n"
                },
                {
                    "idx": 19,
                    "thing": "title",
                    "score": 98.08,
                    "box": [
                        1278.6,
                        453.3,
                        1480.6,
                        494.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_19_title.png",
                    "text": "5.1. Overview\n"
                },
                {
                    "idx": 20,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.0,
                        539.9,
                        2324.6,
                        1410.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_20_text.png",
                    "text": "We have discussed 223 papers on eXplainable Artificial Intelli-\ngence (XAI) for deep learning in medical image analysis. We cat-\negorized the papers based on the XAI-frameworks proposed by\nAdadi and Berrada (2018) and Murdoch et al. (2019). Some trends\nwere noticeable in the surveyed papers. The majority of the pa-\npers used post hoc explanation as contrasted with model-based\nexplanation, i.e., the explanation was provided on a neural net-\nwork that had already been trained, instead of being incorporated\nin neural network training. Both model-specific (e.g., specifically\ndesigned for CNNs) and model-agnostic explanation methods were\nused. Furthermore, most of the papers investigated provided lo-\ncal explanation rather than global explanation, i.e., the explanation\nwas provided per case (e.g. per patient), rather than on a dataset-\nlevel (e.g. for all patients). Since we focus on deep learning in med-\nical image analysis, these trends were to be expected. Most read-\nily available XAI methods suitable for CNNs are saliency mapping\ntechniques, which often provide post hoc, model-specific, and local\nexplanation. Furthermore, post hoc XAI methods can be used after\na neural network has been trained, making them more accessible\nthan model-based XAI.\n"
                },
                {
                    "idx": 21,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.8,
                        1411.3,
                        2326.0,
                        1716.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_21_text.png",
                    "text": "We categorized the papers based on anatomical location and\nmodality of medical imaging. We found that most papers focus on\nchest or brain and on MRI (Fig. 3). This is comparable to what\nLitjens et al. (2017) found for deep learning methods in medical\nimaging in general. This trend is likely due to publicly available\ndatasets in these organs and modalities, and not a reflection of\nhow well explainable these organs and modalities are.\n"
                },
                {
                    "idx": 22,
                    "thing": "title",
                    "score": 98.52,
                    "box": [
                        1277.6,
                        1761.0,
                        1606.8,
                        1803.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_22_title.png",
                    "text": "5.2. Evaluation of XAI\n"
                },
                {
                    "idx": 23,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.5,
                        1847.5,
                        2326.0,
                        2283.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_23_text.png",
                    "text": "We have described several XAI techniques and their appli-\ncations in medical image analysis, but how does one evalu-\nate whether an XAI technique provides good explanation? Un-\nlike measures of performance commonly used in medical im-\nage analysis, such as accuracy, Dice coefficient, or an ROC anal-\nysis; success criteria of explanation are more difficult to define.\nDoshi-Velez and Kim (2017) proposed a framework for the eval-\nuation of explainability, consisting of three evaluation methods:\napplication-grounded evaluation, human-grounded evaluation, and\nfunctionally-grounded evaluation.\n"
                },
                {
                    "idx": 24,
                    "thing": "title",
                    "score": 99.49,
                    "box": [
                        1277.5,
                        2328.3,
                        1853.4,
                        2370.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_24_title.png",
                    "text": "5.2.1. Application-grounded evaluation\n"
                },
                {
                    "idx": 25,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.4,
                        2370.4,
                        2325.5,
                        2762.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_25_text.png",
                    "text": "Application-grounded evaluation uses human experiments\nwithin a real application. In other words, let domain experts test\nthe explanation. In medical image analysis this might involve a ra-\ndiologist inspecting whether example-based explanations are ac-\ntually good examples based on the many images the radiologist\nhas seen in their many years of experience. The advantage of\napplication-grounded evaluation is that it directly tests the objec-\ntive that the system was built for. The disadvantage is that it is a\ncostly evaluation.\n"
                },
                {
                    "idx": 26,
                    "thing": "title",
                    "score": 99.08,
                    "box": [
                        1277.4,
                        2808.1,
                        1800.6,
                        2850.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_26_title.png",
                    "text": "5.2.2. Human-grounded evaluation\n"
                },
                {
                    "idx": 27,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1277.6,
                        2849.8,
                        2326.1,
                        3112.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_13/region_27_text.png",
                    "text": "Human-grounded evaluation uses simpler human experiments\nthat maintain the essence of the target application. In other words,\nlet laypersons test the explanation or a proxy of the explanation.\nFor example, when explaining the location and size of a cancer,\nthis might involve a crowdsourcing project where laypersons judge\nthe quality of saliency maps. Since it uses laypersons instead of\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_14.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_14.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 15,
                "page_idx": 14
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "figure",
                    "score": 99.89,
                    "box": [
                        286.2,
                        235.7,
                        2190.4,
                        1177.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_01_figure.png"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.94,
                    "box": [
                        155.8,
                        1206.9,
                        2326.4,
                        1277.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_02_text.png",
                    "text": "Fig. 3. Papers included in this survey, categorized by modality (left) and anatomical location (right). Papers discussing multiple modalities or anatomical locations were\ngrouped as ‘multiple’. Modalities or anatomical locations that were used in fewer than five papers were grouped as ‘other’.\n"
                },
                {
                    "idx": 3,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        156.2,
                        1352.1,
                        1205.5,
                        1569.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_03_text.png",
                    "text": "highly trained domain experts, the advantage of human-grounded\nevaluation is that it is less costly, while still receiving general no-\ntions of the quality of an explanation. The disadvantage is that the\nassessment of the quality of an explanation is a proxy of the actual\nquality.\n"
                },
                {
                    "idx": 4,
                    "thing": "title",
                    "score": 99.58,
                    "box": [
                        156.0,
                        1606.2,
                        750.7,
                        1647.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_04_title.png",
                    "text": "5.2.3. Functionally-grounded evaluation\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        157.6,
                        1648.6,
                        1205.9,
                        2301.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_05_text.png",
                    "text": "Functionally-grounded evaluation does not use human experi-\nments, but uses other proxies to assess the quality of the explana-\ntion. These proxies may include measurements that have already\nbeen validated using human users. In our example of explaining\nthe location and size of a cancer, this might involve comparing the\nexplanation with manually drawn tumor delineations of a radiolo-\ngist. The advantages of functionally-grounded evaluation stated by\nDoshi-Velez and Kim (2017) include that they are relatively cheap\nto acquire. This is, however, not necessarily the case in medical im-\nage analysis, since acquiring for example manual annotations is a\nvery resource intensive process. When these manual annotations\ndo already exist, e.g. when using curated data from a challenge,\nevaluation of explanations are easily extracted, and can be auto-\nmatically extracted multiple times. This can be useful, for example\nin the development phase of explanation methods.\n"
                },
                {
                    "idx": 6,
                    "thing": "title",
                    "score": 99.67,
                    "box": [
                        158.0,
                        2337.7,
                        911.0,
                        2379.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_06_title.png",
                    "text": "5.2.4. Evaluation of XAI in medical image analysis\n"
                },
                {
                    "idx": 7,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        157.9,
                        2380.3,
                        1205.2,
                        2859.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_07_text.png",
                    "text": "Evaluation of XAI as proposed above is currently not yet stan-\ndard practice in papers in medical image analysis. Furthermore, in\nmedicine a good explanation can differ between areas of expertise\nof the person for whom the explanation is given. For example, a\nvisual explanation pinpointing where disease is located could be\na sufficient explanation for a radiologist or a medical image anal-\nysis researcher. However, clinicians such as an oncologist, neurol-\nogist, or hematologist would probably like to have XAI added to\ntheir clinical decision-making framework. Such framework would\nalso incorporate the patient’s history, previous and current treat-\nments, treatment options, and expected effects or outcomes.\n"
                },
                {
                    "idx": 8,
                    "thing": "title",
                    "score": 98.68,
                    "box": [
                        156.8,
                        2896.3,
                        455.1,
                        2937.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_08_title.png",
                    "text": "5.3. Critique on XAI\n"
                },
                {
                    "idx": 9,
                    "thing": "text",
                    "score": 99.99,
                    "box": [
                        157.0,
                        2981.9,
                        1204.4,
                        3112.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_09_text.png",
                    "text": "Rudin (2019) advised caution when using a black box with ex-\nplanation for high-stakes decision making. Rudin raised several is-\nsues with explaining black boxes. For example, XAI may provide\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1278.2,
                        1352.4,
                        2326.1,
                        1744.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_10_text.png",
                    "text": "an explanation that is not completely faithful to what the origi-\nnal model computes: If the explanation explains 90% true to the\nmodel, that means that 10% is untrue (Rudin, 2019). Furthermore,\nan explanation may not make sense or provide enough detail to\nunderstand what the black box is doing. For example, a saliency\nmap of the class with the highest probability may look similar to\na saliency map of a class with a lower probability. Rudin therefore\nadvices to use interpretable model-based XAI instead, such as the\nprototype network discussed in Section 3.3.3.\n"
                },
                {
                    "idx": 11,
                    "thing": "text",
                    "score": 99.9,
                    "box": [
                        1276.6,
                        1745.2,
                        2326.4,
                        1831.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_11_text.png",
                    "text": "Critiques also often focus on the robustness of XAI techniques,\nas discussed in Section 4.\n"
                },
                {
                    "idx": 12,
                    "thing": "title",
                    "score": 98.43,
                    "box": [
                        1278.7,
                        1893.6,
                        1461.2,
                        1935.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_12_title.png",
                    "text": "5.4. Outlook\n"
                },
                {
                    "idx": 13,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        1278.0,
                        1979.8,
                        2326.5,
                        2327.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_13_text.png",
                    "text": "Since high stakes decision-making is intertwined with\nmedicine, we are convinced that XAI will be increasingly im-\nportant. We have investigated the trends, and noticed that an\nincreasing amount of papers contain a holistic approach, combin-\ning multiple forms of explanation. Examples of such more holistic\napproaches include combinations of textual explanation and visual\nexplanation (e.g. Graziani et al., 2020), or combinations of example\nbased explanation and visual explanation (e.g. Wang et al., 2019).\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1276.9,
                        2328.6,
                        2324.5,
                        2808.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_14_text.png",
                    "text": "Future directions of XAI in medical image analysis may in-\nclude biological explanation. Several researchers have predicted\nbiological processes from imaging features using deep learning.\nFor example, Matsui et al. (2020) predicted the molecular sub-\ntype of lower-grade gliomas on multimodal brain imaging, and\nZhu et al. (2019) predicted the molecular subtype luminal A of\nbreast cancer on MRI. These analyses used a biological target to\ntrain the neural network. However, performing such analysis the\nother way around, for example by performing a pathway analysis\non imaging phenotypes (e.g. Bismeijer et al. (2020), not deep learn-\ning), could provide interesting biological explanation.\n"
                },
                {
                    "idx": 15,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        1278.1,
                        2809.0,
                        2326.0,
                        3111.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_14/region_15_text.png",
                    "text": "XAI may also be useful to aid physicians in the diagnostic pro-\ncess or in identifying unknown information from medical images.\nFor example, a study on the diagnosis of tuberculosis on chest X-\nrays showed that 10 out of the 13 participating physicians (77%)\nhad better diagnostic accuracy when assessing chest X-rays with\nan XAI providing a visual explanation compared to assessing the\nchest X-ray without XAI (Rajpurkar et al., 2020a).\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_15.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_15.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 32,
                "page_idx": 15
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 99.95,
                    "box": [
                        156.4,
                        233.9,
                        1205.1,
                        538.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_01_text.png",
                    "text": "It is likely that XAI in medical imaging will increasingly in-\nclude domain information. To reach this goal, physicians should\nbe included when designing task-specific interpretation methods\n(Fan et al., 2021). Active collaboration among physicians, theoreti-\ncal researchers, medical imaging experts, and medical image anal-\nysis experts will be an important avenue for future development\nof deep learning methods (Fan et al., 2021).\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 99.93,
                    "box": [
                        158.0,
                        539.5,
                        1205.7,
                        1451.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_02_text.png",
                    "text": "Other directions of XAI in medical image analysis may include\nthe link between causality and XAI. Typical medical image analy-\nsis consists of correlation rather than causation. Causality describes\nthe relation between cause and effect, and can be mathematically\ndescribed (Pearl, 2009). Current XAI techniques that aim to be free\nof bias such as prototypes are potentially still sensitive to differ-\nences in training population, which might hamper generalizability.\nCastro et al. (2020) describe how causal reasoning may be useful\nto assess biases in the data. DeGrave et al. (2021) gave an exam-\nple how dataset bias can be detected using XAI: In studies that\ndistinguish between X-rays of patients who were Coronavirus dis-\nease 2019 (COVID-19)-positive and of patients who were COVID-\n19-negative, they used visual explanation to demonstrate that high\nperformance of the deep learning models was actually attributed\nto how the datasets were composed, rather than to actual COVID-\n19 detection in the X-rays. van Amsterdam et al. (2019) show an\nexample of eliminating bias using causality, yielding unbiased pre-\ndiction of prognosis for patients with lung cancer. It would be of\ninterest to incorporate such analyses in explanation of medical im-\nages, as Chattopadhyay et al. (2019) have done for visual explana-\ntion of MNIST data.\n"
                },
                {
                    "idx": 3,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.6,
                        1455.7,
                        1205.0,
                        1715.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_03_text.png",
                    "text": "There is no consensus on a priori estimations for required sam-\nple size for XAI and deep learning in medical imaging in general\n(Balki et al., 2019). Given the costly nature of acquiring medical\nimaging datasets in terms of money, time, and patient burden, it is\ndesired to have guidelines describing what minimum sample sizes\nwould be required for which XAI techniques.\n"
                },
                {
                    "idx": 4,
                    "thing": "title",
                    "score": 98.71,
                    "box": [
                        157.1,
                        1784.3,
                        389.8,
                        1825.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_04_title.png",
                    "text": "5.5. Limitations\n"
                },
                {
                    "idx": 5,
                    "thing": "text",
                    "score": 99.96,
                    "box": [
                        158.1,
                        1869.8,
                        1204.9,
                        2391.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_05_text.png",
                    "text": "We derived our XAI framework from the frameworks of\nAdadi and Berrada (2018) and Murdoch et al. (2019). Other frame-\nworks also exist, such as the framework by Kim et al. that di-\nvides XAI in pre-, during-, and post-model explanation. During-\nand post-model explanation are captured by our XAI framework\nwith model-based and post hoc explanation. Pre-model explana-\ntion mainly focuses on the structure of a dataset, such as inspect-\ning outliers. One could state that an example-based explanation\nthat utilizes the latent distributions of a dataset could be perceived\nas a pre-model explanation. We have, however, not made this dis-\ntinction, since in deep learning, these latent distributions are dis-\ncovered by training a neural network.\n"
                },
                {
                    "idx": 6,
                    "thing": "text",
                    "score": 99.97,
                    "box": [
                        156.7,
                        2393.0,
                        1205.6,
                        2696.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_06_text.png",
                    "text": "We tried to be as comprehensive as possible with the inclusion\nof papers in our survey. However, XAI often is a technique used\nto support methods, and keywords are often not mentioned in the\ntitle or body of papers (Rudin, 2019). Therefore, we cannot guar-\nantee that we covered all the work in the field. Nevertheless, we\nprovided the search strategy to be as transparent as possible about\nthe selection of papers.\n"
                },
                {
                    "idx": 7,
                    "thing": "title",
                    "score": 98.74,
                    "box": [
                        156.2,
                        2764.2,
                        380.2,
                        2806.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_07_title.png",
                    "text": "6. Conclusion\n"
                },
                {
                    "idx": 8,
                    "thing": "text",
                    "score": 99.98,
                    "box": [
                        157.0,
                        2850.4,
                        1204.5,
                        3111.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_08_text.png",
                    "text": "This paper surveyed 223 papers using explainable artificial in-\ntelligence (XAI) in deep-learning based medical image analysis,\nclassified according to an XAI framework, and categorized accord-\ning to anatomical location and imaging technique. The paper dis-\ncussed how to evaluate XAI, current critiques on XAI, and future\nperspectives for XAI in medical image analysis.\n"
                },
                {
                    "idx": 9,
                    "thing": "title",
                    "score": 98.68,
                    "box": [
                        1277.5,
                        233.5,
                        1655.5,
                        276.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_09_title.png",
                    "text": "Additional information\n"
                },
                {
                    "idx": 10,
                    "thing": "text",
                    "score": 99.81,
                    "box": [
                        1275.6,
                        320.9,
                        2324.6,
                        406.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_10_text.png",
                    "text": "This work was partially funded by the Dutch Cancer Society\n(KWF) Grant No.: 10755. We have no conflicts of interest.\n"
                },
                {
                    "idx": 11,
                    "thing": "title",
                    "score": 99.0,
                    "box": [
                        1276.2,
                        468.4,
                        1834.4,
                        510.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_11_title.png",
                    "text": "Declaration of Competing Interest\n"
                },
                {
                    "idx": 12,
                    "thing": "text",
                    "score": 99.93,
                    "box": [
                        1278.7,
                        554.3,
                        2325.7,
                        685.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_12_text.png",
                    "text": "The authors declare that they have no known competing finan-\ncial interests or personal relationships that could have appeared to\ninfluence the work reported in this paper.\n"
                },
                {
                    "idx": 13,
                    "thing": "title",
                    "score": 97.43,
                    "box": [
                        1277.4,
                        735.2,
                        1452.9,
                        776.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_13_title.png",
                    "text": "References\n"
                },
                {
                    "idx": 14,
                    "thing": "text",
                    "score": 66.62,
                    "box": [
                        1277.9,
                        820.4,
                        2323.6,
                        884.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_14_text.png",
                    "text": "Abbasi-Asl, Reza, Yu, Bin, 2017. Structural compression of convolutional neural net-\nworks arXiv preprint arXiv:1705.07356.\n"
                },
                {
                    "idx": 15,
                    "thing": "text",
                    "score": 77.53,
                    "box": [
                        1277.5,
                        885.4,
                        2327.7,
                        985.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_15_text.png",
                    "text": "Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P., Siisstrunk, S., 2012. SLIC superpix-\nels compared to state-of-the-art superpixel methods. IEEE Trans. Pattern Anal.\nMach. Intell. 34, 2274-2281. doi: 10.1109/TPAMI.2012.120.\n"
                },
                {
                    "idx": 16,
                    "thing": "text",
                    "score": 79.05,
                    "box": [
                        1277.2,
                        985.1,
                        2326.9,
                        1084.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_16_text.png",
                    "text": "Adadi, A., Berrada, M., 2018. Peeking Inside the Black-Box: A Survey on Explainable\nArtificial Intelligence (XAI). IEEE Access 6, 52138-52160. doi:10.1109/ACCESS.\n2018.2870052.\n"
                },
                {
                    "idx": 17,
                    "thing": "text",
                    "score": 80.36,
                    "box": [
                        1277.3,
                        1085.5,
                        2325.9,
                        1184.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_17_text.png",
                    "text": "Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., Kim, B., 2018. Sanity\nchecks for saliency maps. Advances in neural information processing systems,\np. 31.\n"
                },
                {
                    "idx": 18,
                    "thing": "text",
                    "score": 87.23,
                    "box": [
                        1279.9,
                        1185.2,
                        2325.5,
                        1316.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_18_text.png",
                    "text": "Ahmad, A., Sarkar, S., Shah, A., Gore, S., Santosh, V., Saini, J., Ingalhalikar, M., 2019.\nPredictive and discriminative localization of IDH genotype in high grade gliomas\nusing deep convolutional neural nets. In: Proceedings of the IEEE 16th Interna-\ntional Symposium on Biomedical Imaging (ISBI 2019), pp. 372-375.\n"
                },
                {
                    "idx": 19,
                    "thing": "text",
                    "score": 89.47,
                    "box": [
                        1281.1,
                        1318.7,
                        2324.9,
                        1415.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_19_text.png",
                    "text": "Ahmad, M., Kasukurthi, N., Pande, H., 2019. Deep learning for weak supervision of\ndiabetic retinopathy abnormalities. In: Proceedings of the IEEE 16th Interna-\ntional Symposium on Biomedical Imaging (ISBI), pp. 573-577.\n"
                },
                {
                    "idx": 20,
                    "thing": "text",
                    "score": 89.56,
                    "box": [
                        1279.4,
                        1418.6,
                        2325.7,
                        1587.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_20_text.png",
                    "text": "Akselrod-Ballin, A., Chorev, M., Shoshan, Y., Spiro, A.. Hazan, A., Melamed, R.,\nBarkan, E., Herzel, E., Naor, S., Karavani, E., Koren, G., Goldschmidt, Y., Shalev, V.,\nRosen-Zvi, M., Guindy, M., 2019. Predicting breast cancer by applying deep\nlearning to linked health records and mammograms. Radiology 292, 331-342.\ndoi: 10.1148 /radiol.2019182622.\n"
                },
                {
                    "idx": 21,
                    "thing": "text",
                    "score": 83.94,
                    "box": [
                        1278.1,
                        1585.0,
                        2325.1,
                        1681.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_21_text.png",
                    "text": "Allaouzi, I., Ben Ahmed, M., Benamrou, B., Ouardouz, M., 2018. Automatic caption\ngeneration for medical images. In: Proceedings of the 3rd International Confer-\nence on Smart City Applications, pp. 1-6. :\n"
                },
                {
                    "idx": 22,
                    "thing": "text",
                    "score": 91.37,
                    "box": [
                        1279.7,
                        1680.0,
                        2324.5,
                        1815.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_22_text.png",
                    "text": "Aratijo, T., Aresta, G., Mendonca, L., Penas, S., Maia, C., Carneiro, A., Mendonca, A.M.,\nCampilho, A., 2020. DRJGRADUATE: uncertainty-aware deep learning-based di-\nabetic retinopathy grading in eye fundus images. Med. Image Anal. 63. doi:10.\n1016/j.media.2020.101715.\n"
                },
                {
                    "idx": 23,
                    "thing": "text",
                    "score": 67.8,
                    "box": [
                        1278.3,
                        1816.8,
                        2327.2,
                        1908.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_23_text.png",
                    "text": "Arun, N., Gaw, N., Singh, P., Chang, K., Aggarwal, M., Chen, B., Hoebel, K., Gupta, S.,\nPatel, J., Gidwani, M., 2021. Assessing the (un) trustworthiness of saliency maps\nfor localizing abnormalities in medical imaging. Radiol. Artif. Intell., e200267.\n"
                },
                {
                    "idx": 24,
                    "thing": "text",
                    "score": 53.87,
                    "box": [
                        1275.0,
                        1915.2,
                        2328.0,
                        2046.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_24_text.png",
                    "text": "Ausawalaithong, W., Thirach, A., Marukatat, S., Wilaiprasitporn, T., 2018. Automatic\nlung cancer prediction from chest X-ray images using the deep learning ap-\nproach. In: Proceedings of the 11th Biomedical Engineering International Con-\nference (BMEICON), pp. 1-5.\n"
                },
                {
                    "idx": 25,
                    "thing": "text",
                    "score": 77.84,
                    "box": [
                        1279.0,
                        2046.5,
                        2326.6,
                        2147.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_25_text.png",
                    "text": "Bach, S., Binder, A., Montavon, G., Klauschen, F., Miller, K.R., Samek, W., 2015. On\npixel-wise explanations for non-linear classifier decisions by layer-wise rele-\nvance propagation. PLoS One 10, 1-46. doi:10.1371/journal.pone.0130140.\n"
                },
                {
                    "idx": 26,
                    "thing": "text",
                    "score": 80.55,
                    "box": [
                        1279.4,
                        2142.1,
                        2326.8,
                        2414.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_26_text.png",
                    "text": "Balki, I., Amirabadi, A., Levman, J., Martel, A.L., Emersic, Z., Meden, B., Garcia-\nPedrero, A., Ramirez, S.C., Kong, D., Moody, A.R., Tyrrell, P.N., 2019. Sample-\nsize determination methodologies for machine learning in medical imaging re-\nsearch: a systematic review. Can. Assoc. Radiol. J. doi:10.1016/j.carj.2019.06.002.\n\nBanerjee, S., Lavie, A., 2005. METEOR: An automatic metric for MT evaluation with\nimproved correlation with human judgments. In: Proceedings of the ACL Work-\nshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation\nand/or Summarization, pp. 65-72.\n"
                },
                {
                    "idx": 27,
                    "thing": "text",
                    "score": 77.35,
                    "box": [
                        1278.0,
                        2412.5,
                        2326.5,
                        2479.7
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_27_text.png",
                    "text": "Barata, C., Celebi, M.E., Marques, J.S., 2020. Explainable skin lesion diagnosis using\ntaxonomies. Pattern Recognit. doi:10.1016/j.patcog.2020.107413.\n"
                },
                {
                    "idx": 28,
                    "thing": "text",
                    "score": 91.89,
                    "box": [
                        1279.9,
                        2476.8,
                        2325.9,
                        2645.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_28_text.png",
                    "text": "Baumgartner, C.F, Koch, L.M., Tezcan, K.C., Ang, J.X., Konukoglu, E., 2018. Visual fea-\nture attribution using Wasserstein GANs. In: Proceedings of the 31st Meeting\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR\n2018, Switzerland, pp. 8309-8319. doi:10.1109/CVPR.2018.00867 IEEE Computer\nSociety, Computer Vision Lab, ETH Zurich.\n"
                },
                {
                    "idx": 29,
                    "thing": "text",
                    "score": 79.47,
                    "box": [
                        1280.4,
                        2646.7,
                        2325.5,
                        2744.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_29_text.png",
                    "text": "Bian, Z., Xia, S., Xia, C., Shao, M., 2019. Weakly supervised vitiligo segmentation in\nskin image through saliency propagation. In: Proceedings of the IEEE Interna-\ntional Conference on Bioinformatics and Biomedicine (BIBM), pp. 931-934.\n"
                },
                {
                    "idx": 30,
                    "thing": "text",
                    "score": 82.99,
                    "box": [
                        1278.3,
                        2757.6,
                        2326.3,
                        2878.3
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_30_text.png",
                    "text": "DICH, IN., NajPUIKal, F., Dall, NL, LEVIL, J., Falk, /i., JULES, £., DELCKEL, IVI, Pal€l, D.IN.,\nYeom, K.W., Shpanskaya, K., et al., 2018. Deep-learning-assisted diagnosis for\nknee magnetic resonance imaging: development and retrospective validation of\nMRNet. PLoS Med. 15, e1002699.\n"
                },
                {
                    "idx": 31,
                    "thing": "text",
                    "score": 92.4,
                    "box": [
                        1281.7,
                        2876.1,
                        2324.9,
                        3043.5
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_31_text.png",
                    "text": "Biff, C., Doumou, G., Duan, J., Prasad, S.K., Cook, S.A. O Regan, D.P., Rueckert, D.,\nCerrolaza, J.J., Tarroni, G., Bai, W., De Marvao, A., Oktay, O., Ledig, C., Le Fol-\ngoc, L., Kamnitsas, K., 2020. Explainable anatomical shape analysis through deep\nhierarchical generative models. IEEE Trans. Med. Imaging doi:10.1109/tmi.2020.\n2964499, 1-1.\n"
                },
                {
                    "idx": 32,
                    "thing": "text",
                    "score": 82.18,
                    "box": [
                        1274.5,
                        3043.1,
                        2327.2,
                        3110.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_15/region_32_text.png",
                    "text": "Bismeijer, T., van der Velden, B.H.M., Canisius, S., Lips, E.H., Loo, C.E., Viergever, M.A.,\nWesseling, J., Gilhuijs, K.G.A.. Wessels, L.A. 2020. Radiogenomic analysis of\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_16.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_16.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 2,
                "page_idx": 16
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "list",
                    "score": 57.43,
                    "box": [
                        151.8,
                        235.4,
                        1206.6,
                        3049.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_16/region_1_list.png",
                    "text": "breast cancer by linking mri phenotypes with tumor gene expression. Radiol-\nogy 296, 277-287. doi:10.1148/radiol.2020191453.\n\nBohle, M., Eitel, F., Weygandt, M., Ritter, K.Initiative, on behalf of the A.D.N., 2019.\nLayer-wise relevance propagation for explaining deep neural network deci-\nsions in MRI-based Alzheimer’s disease classification. Front. Aging Neurosci. 10.\ndoi:10.3389/fnagi.2019.00194.\n\nBrunese, L., Mercaldo, F., Reginelli, A., Santone, A., 2020. Explainable deep learning\nfor pulmonary disease and coronavirus COVID-19 detection from X-rays. Com-\nput. Methods Progr. Biomed. 196. doi:10.1016/j.cmpb.2020.105608.\n\nCandemir, S., White, R.D., Demirer, M., Gupta, V., Bigelow, M.T., Prevedello, L.M.,\nErdal, B.S., 2020. Automated coronary artery atherosclerosis detection and\nweakly supervised localization on coronary CT angiography with a deep 3-\ndimensional convolutional neural network. Comput. Med. Imaging Graph. 83.\ndoi:10.1016/j.compmedimag.2020.101721.\n\nCastro, D.C., Walker, I., Glocker, B., 2020. Causality matters in medical imaging. Nat.\nCommun. 11, 1-10. doi:10.1038/s41467-020- 17478-w.\n\nCeschin, R., Zahner, A., Reynolds, W., Gaesser, J., Zuccoli, G., Lo, C.W., Gopalakrish-\nnan, V., Panigrahy, A., 2018. A computational framework for the detection of\nsubcortical brain dysmaturation in neonatal MRI using 3D convolutional neural\nnetworks. Neuroimage 178, 183-197.\n\nChakraborty, S., Aich, S., Kim, H.C., 2020. Detection of Parkinson’s disease from 3T\nt1 weighted MRI scans using 3D convolutional neural network. Diagnostics 10,\n402.\n\nChan, L., Hosseini, M.S., Rowsell, C., Plataniotis, K.N., Damaskinos, S., 2019. Histoseg-\nnet: Semantic segmentation of histological tissue type in whole slide images.\nIn: Proceedings of the IEEE/CVF International Conference on Computer Vision,\npp. 10662-10671.\n\nChang, G.H., Felson, D.T., Qiu, S., Guermazi, A., Capellini, T.D., Kolachalama, V.B.,\n2020. Assessment of knee pain from MR imaging using a convolutional Siamese\nnetwork. Eur. Radiol. 1-11.\n\nChattopadhyay, A., Manupriya, P., Sarkar, A., Balasubramanian, V.N., 2019. Neural\nnetwork attributions: A causal perspective. In: International Conference on Ma-\nchine Learning. PMLR, pp. 981-990.\n\nChen, B., Li, J., Lu, G., Zhang, D., 2019. Lesion location attention guided network for\nmulti-label thoracic disease classification in chest X-rays. IEEE J. Biomed. Health\nInform. 24, 2016-2027.\n\nChen, C., Li, O., Tao, D., Barnett, A., Rudin, C., Su, J.K., 2019. This looks like that:\ndeep learning for interpretable image recognition, in: Wallach, H., Larochelle,\nH., Beygelzimer, A., d\\textquotesingle Alché-Buc, F., Fox, E., Garnett, R. (Eds.),\nAdvances in Neural Information Processing Systems 32. Curran Associates, Inc.,\npp. 8930-8941.\n\nChen, P., Shi, X., Liang, Y., Li, Y., Yang, L., Gader, P.D., 2020. Interactive thyroid whole\nslide image diagnostic system using deep representation. Comput. Methods Pro-\ngrams Biomed. 195. doi:10.1016/j.cmpb.2020.105630.\n\nChen, X., Lin, L, Liang, D., Hu, H., Zhang, Q., Iwamoto, Y., Han, X.H., Chen, Y.W.,\nTong, R., Wu, J., 2019. A dual-attention dilated residual network for liver lesion\nclassification and localization on CT images. In: Proceedings of the IEEE Inter-\nnational Conference on Image Processing (ICIP), pp. 235-239.\n\nCheng, C.T., Ho, T.-Y., Lee, T-Y., Chang, C.C., Chou, C.C., Chen, C.C., Chung, IF, Liao, C.H.,\n2019. Application of a deep learning algorithm for detection and visualization of\nhip fractures on plain pelvic radiographs. Eur. Radiol. 29, 5469-5477.\n\nCheplygina, V., de Bruijne, M., Pluim, J.P.W., 2019. Not-so-supervised: a survey of\nsemi-supervised, multi-instance, and transfer learning in medical image analy-\nsis. Med. Image Anal. 54, 280-296. doi:10.1016/j.media.2019.03.009.\n\nChoi, H., Kim, Y.K., Yoon, EJ., Lee, J-Y., Lee, D.S., 2020. Cognitive signature of brain\nFDG PET based on deep learning: domain transfer from Alzheimer’s disease to\nParkinson's disease. Eur. J. Nucl. Med. Mol. Imaging 47, 403-412.\n\nChoudhary, A., Wu, H., Tong, L., Wang, M.D., 2019. Learning to evaluate color sim-\nilarity for histopathology images using triplet networks. In: Proceedings of the\n10th ACM International Conference on Bioinformatics, Computational Biology\nand Health Informatics, pp. 466-474.\n\nClough, J.R., Oksuz, I., Puyol-Anton, E., Ruijsink, B., King, A.P., Schnabel, J.A., 2019.\nGlobal and local interpretability for cardiac MRI classification. In: Proceedings of\nthe 22nd International Conference on Medical Image Computing and Computer-\nAssisted Intervention MICCAI 2019 doi:10.1007/978-3-030-32251-9_72.\n\nCodella, N.C.F, Lin, C.C., Halpern, A., Hind, M., Feris, R., Smith, J.R., 2018. Collab-\norative human-Al (CHAI): Evidence-based interpretable melanoma classifica-\ntion in dermoscopic images. In: Proceedings of the 1st International Work-\nshop on Machine Learning in Clinical Neuroimaging, MLCN 2018 doi:10.1007/\n978-3-030-02628-8_11, 1st Int. Work. Deep Learn. Fail. DLF 2018, 1st Int. Work.\nInterpret. Mach. Intell. Med. Image Comput. iMIMIC.\n\nCong, C., Kato, Y., Vasconcellos, H.D., Lima, J., Venkatesh, B., 2019. Automated Steno-\nsis Detection and Classification in X-ray Angiography Using Deep Neural Net-\nwork. In: Proceedings of the IEEE International Conference on Bioinformatics\nand Biomedicine (BIBM), pp. 1301-1308.\n\nCook, R.D., Weisberg, S., 1980. Characterizations of an empirical influence function\nfor detecting influential cases in regression. Technometrics 22, 495. doi:10.2307/\n1268187.\n\nCosta, P. Araujo, T., Aresta, G., Galdran, A. Mendonca, A.M., Smailagic, A.,\nCampilho, A., 2019. EyeWeS: weakly supervised pre-trained convolutional neu-\nral networks for diabetic retinopathy detection. In: Proceedings of the 16th\nInternational Conference on Machine Vision Applications, MVA 2019. Portu-\ngal doi:10.23919/MVA.2019.8757991, Institute of Electrical and Electronics En-\ngineers Inc., INESC TEC.\n"
                },
                {
                    "idx": 2,
                    "thing": "list",
                    "score": 58.15,
                    "box": [
                        1274.3,
                        225.2,
                        2328.0,
                        3028.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_16/region_2_list.png",
                    "text": "Dang, S., Chaudhury, S., 2019. Novel relative relevance score for estimating brain\nconnectivity from fMRI data using an explainable neural network approach. J.\nNeurosci. Methods 326. doi:10.1016/j.jneumeth.2019.108371.\n\nde Vos, B.D., Wolterink, J.M., Leiner, T., de Jong, P.A., Lessmann, N., Isgum, I., 2019.\nDirect automatic coronary calcium scoring in cardiac and chest CT. IEEE Trans.\nMed. Imaging 38, 2127-2138. doi:10.1109/TMI.2019.2899534.\n\nDeGrave, AJ., Janizek, J.D., Lee, S.I., 2021. AI for radiographic COVID-19 detection\nselects shortcuts over signal. Nat. Mach. Intell. 3, 610-619.\n\nDietterich, T.G., Lathrop, R.H., Lozano-Pérez, T., 1997. Solving the multiple in-\nstance problem with axis-parallel rectangles. Artif. Intell. 89, 31-71. doi:10.1016/\ns0004-3702(96)00034-3.\n\nDoshi-Velez, F., Kim, B., 2017. Towards a rigorous science of interpretable machine\nlearning arXiv preprint arXiv:1702.08608.\n\nDubost, F., Adams, H., Bortsova, G., Ikram, M.A., Niessen, W., Vernooij, M., de Brui-\njne, M., 2019a. 3D regression neural network for the quantification of enlarged\nperivascular spaces in brain MRI. Med. Image Anal. 51, 89-100.\n\nDubost, F, Adams, H., Yilmaz, P., Bortsova, G. van Tulder, G., Ikram, M.A,\nNiessen, W., Vernooij, M.W., de Bruijne, M., 2020. Weakly supervised object\ndetection with 2D and 3D regression neural networks. Med. Image Anal. 65,\n101767.\n\nDubost, F., Yilmaz, P., Adams, H., Bortsova, G., Ikram, M.A., Niessen, W., Vernooij, M.,\nDe Bruijne, M., 2019b. Enlarged perivascular spaces in brain MRI: Automated\nquantification in four regions. Neuroimage 185, 534-544.\n\nDunnmon, J.A., Yi, D., Langlotz, C.P., Ré, C., Rubin, D.L., Lungren, M.P., 2019. Assess-\nment of convolutional neural networks for automated classification of chest ra-\ndiographs. Radiology 290, 537-544.\n\nEitel, F, Ritter, K., 2019. Testing the robustness of attribution methods for convo-\nlutional neural networks in MRI-based Alzheimer’s disease classification. In:\nLecture Notes in Computer Science (Including Subseries Lecture Notes in Ar-\ntificial Intelligence and Lecture Notes in Bioinformatics). Springer, pp. 3-11.\ndoi: 10.1007 /978-3-030-33850-3_1.\n\nEitel, F, Soehler, E., Bellmann-Strobl, J., Brandt, A.U., Ruprecht, K., Giess, R.M., Kuch-\nling, J., Asseyer, S., Weygandt, M., Haynes, J.D., Scheel, M., Paul, F, Ritter, K.,\n2019. Uncovering convolutional neural network decisions for diagnosing multi-\nple sclerosis on conventional MRI using layer-wise relevance propagation. Neu-\nrolmage Clin. 24. doi:10.1016/j.nicl.2019.102003.\n\nEl Adoui, M., Drisis, S., Benjelloun, M., 2020. Multi-input deep learning architecture\nfor predicting breast tumor response to chemotherapy using quantitative MR\nimages. Int. J. Comput. Assist. Radiol. Surg. 15, 1491-1500.\n\nEverson, M., Herrera, L.C.G.P., Li, W., Luengo, I.M., Ahmad, O., Banks, M., Magee, C.,\nAlzoubaidi, D., Hsu, H.M., Graham, D., Vercauteren, T., Lovat, L., Ourselin, S.,\nKashin, S., Wang, H.P, Wang, W.L., Haidry, RJ. 2019. Artificial intelligence\nfor the real-time classification of intrapapillary capillary loop patterns in\nthe endoscopic diagnosis of early oesophageal squamous cell carcinoma: A\nproof-of-concept study. United Eur. Gastroenterol. J. 7, 297-306. doi:10.1177/\n2050640618821800.\n\nFan, F.L., Xiong, J., Li, M., Wang, G., 2021. On interpretability of artificial neural net-\nworks: a survey. IEEE Trans. Radiat. Plasma Med. Sci. 5, 741-760.\n\nFong, R.C., Vedaldi, A., 2017. Interpretable Explanations of Black Boxes by Meaning-\nful Perturbation. In: Proceedings of the IEEE International Conference on Com-\nputer Vision (ICCV).\n\nFuchigami, T., Akahori, S., Okatani, T., Li, Y., 2020. A hyperacute stroke segmentation\nmethod using 3D U-Net integrated with physicians’ knowledge for NCCT. In:\nMedical Imaging 2020: Computer-Aided Diagnosis, 11314. International Society\nfor Optics and Photonics.\n\nGao, K., Shen, H., Liu, Y., Zeng, L., Hu, D., 2019. Dense-CAM: visualize the gender of\nbrains with MRI images. In: Proceedings of the International Joint Conference\non Neural Networks (IJCNN), pp. 1-7.\n\nGao, Y., Zhang, Y., Wang, H., Guo, X., Zhang, J., 2019. Decoding behavior tasks from\nbrain activity using deep transfer learning. IEEE Access 7, 43222-43232. doi:10.\n1109/ACCESS.2019.2907040.\n\nGarcia-Peraza-Herrera, L.C., Everson, M., Lovat, L., Wang, H.P., Wang, W.L., Haidry, R.,\nStoyanov, D., Ourselin, S. Vercauteren, T., 2020. Intrapapillary capillary\nloop classification in magnification endoscopy: open dataset and baseline\nmethodology. Int. J. Comput. Assist. Radiol. Surg. 15, 651-659. doi:10.1007/\n$11548-020-02127-w.\n\nGasimova, A., 2019. Automated enriched medical concept generation for chest X-ray\nimages. In: Proceedings of the Interpretability of Machine Intelligence in Med-\nical Image Computing and Multimodal Learning for Clinical Decision Support:\nSecond International Workshop, iMIMIC 2019, and 9th International Workshop,\nML-CDS , Held in Conjunction with MICCAI doi:10.1007/978-3-030-33850-3_10.\n\nGecer, B., Aksoy, S., Mercan, E., Shapiro, L.G., Weaver, D.L., Elmore, J.G., 2018. De-\ntection and classification of cancer in whole slide breast histopathology images\nusing deep convolutional networks. Pattern Recognit. 84, 345-356.\n\nGessert, N., Latus, S., Abdelwahed, Y.S., Leistner, D.M., Lutz, M., Schlaefer, A., 2019.\nBioresorbable scaffold visualization in IVOCT images using CNNs and weakly su-\npervised localization. In: Medical Imaging 2019: Image Processing, 10949. SPIE,\npp. 606-612.\n\nGraziani, M., Andrearczyk, V.S.M.M., Miiller, H., 2020. Concept attribution: ex-\nplaining CNN decisions to physicians. Comput. Biol. Med. 123. doi:10.1016/j.\ncompbiomed.2020.103865.\n\nGrigorescu, I., Cordero-Grande, L., David Edwards, A., Hajnal, J.V, Modat, M., De-\nprez, M., 2019. Investigating image registration impact on preterm birth clas-\nsification: An interpretable deep learning approach. In: Proceedings of the\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_17.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_17.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 2,
                "page_idx": 17
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "list",
                    "score": 53.1,
                    "box": [
                        149.0,
                        241.7,
                        1206.6,
                        3047.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_17/region_1_list.png",
                    "text": "1st International Working Smart Ultrasound Imaging, SUSI 2019 doi:10.1007/\n978-3-030-32875-7_12, 4th Int. Work. Preterm, Perinat. Paediatr. Image Anal.\nPIPPI 2019, held conjunction with 22nd Int. Conf. Med. Imaging Comput.\n\nGuo, H., Kruger, M., Wang, G., Kalra, M.K., Yan, P., 2020. Multi-task learning for mor-\ntality prediction in LDCT images. Med. Imag. Comput. Aided Diagn., 113142C.\nGupta, M., Das, C., Roy, A., Gupta, P., Pillai, G.R. Patole, K., 2020. Region of inter-\nest identification for cervical cancer images. In: Proceedings of the IEEE 17th\n\nInternational Symposium on Biomedical Imaging (ISBI), pp. 1293-1296.\n\nGupta, V., Demirer, M., Bigelow, M., Sarah, M.Y., Joseph, S.Y., Prevedello, L.M.,\nWhite, R.D., Erdal, B.S., 2020. Using transfer learning and class activation maps\nsupporting detection and localization of femoral fractures on anteroposterior\nradiographs. In: Proceedings of the IEEE 17th International Symposium on\nBiomedical Imaging (ISBI), pp. 1526-1529.\n\nGV, K.K., Reddy, G.M., 2019. Automatic classification of whole slide pap smear im-\nages using CNN with PCA based feature interpretation. In: Proceedings of the\nCVPR Workshops, pp. 1074-1079.\n\nHagele, M., Seegerer, P., Lapuschkin, S., Bockmayr, M., Samek, W., Klauschen, F.,\nMiiller, K.R., Binder, A., 2020. Resolving challenges in deep learning-based anal-\nyses of histopathological images using explanation methods. Sci. Rep. 10. doi:10.\n1038/s41598-020-62724-2.\n\nHe, J., Shang, L., Ji, H., Zhang, X., 2017. Deep learning features for lung adenocarci-\nnoma classification with tissue pathology images. In: Proceedings of the Inter-\nnational Conference on Neural Information Processing, pp. 742-751.\n\nHeinemann, F.,, Birk, G., Stierstorfer, B., 2019. Deep learning enables pathologist-like\nscoring of NASH models. Sci. Rep. 9, 1-10.\n\nHilbert, A., Ramos, LA. van Os, HJ.A., Olabarriaga, S.D., Tolhuisen, M.L., Wer-\nmer, MJ.H., Barros, R.S., van der Schaaf, I., Dippel, D., Roos, Y., et al., 2019. Data—\nefficient deep learning of radiological image data for outcome prediction after\nendovascular treatment of patients with acute ischemic stroke. Comput. Biol.\nMed. 115, 103516.\n\nHochreiter, S., Schmidhuber, J., 1997. Long short-term memory. Neural Comput. 9,\n1735-1780.\n\nHoffer, E., Ailon, N., 2015. Deep metric learning using triplet network. In: Proceed-\nings of the International Workshop on Similarity-Based Pattern Recognition,\npp. 84-92.\n\nHosny, A., Parmar, C., Coroller, T.P., Grossmann, P., Zeleznik, R., Kumar, A., Bussink, J.,\nGillies, RJ., Mak, R.H., Aerts, H,J.W.L., 2018. Deep learning for lung cancer\nprognostication: a retrospective multi-cohort radiomics study. PLoS Med. 15,\ne1002711.\n\nHuang, Y., Chung, A.C.S., 2019. Evidence localization for pathology images using\nweakly supervised learning. In: Proceedings of the International Conference on\nMedical Image Computing and Computer-Assisted Intervention, pp. 613-621.\n\nHuang, Z., Fu, D., 2019. Diagnose chest pathology in X-ray images by learning\nmulti-attention convolutional neural network. In: Proceedings of the IEEE 8th\nJoint International Information Technology and Artificial Intelligence Conference\n(ITAIC), pp. 294-299.\n\nHuang, Z., Zhu, X., Ding, M., Zhang, X., 2020. Medical image classification using a\nlight-weighted hybrid neural network based on PCANet and DenseNet. IEEE Ac-\ncess. 8, 24697-24712.\n\nHuff, D.T., Weisman, A,J., Jeraj, R., 2021. Interpretation and visualization techniques\nfor deep learning models in medical imaging. Phys. Med. Biol. 66, O4TRO1.\nHumphries, S.M., Notary, A.M., Centeno, J.P., Strand, M.J., Crapo, J.D., Silverman, E.K.,\nLynch, D.A.of COPD (COPDGene) Investigators, G.E., 2020. Deep learning enables\nautomatic classification of emphysema pattern at CT. Radiology 294, 434-444.\n\nHuo, Y., Terry, J.G., Wang, J., Nath, V., Bermudez, C., Bao, S., Parvathaneni, P., Carr, J,J.,\nLandman, B.A., 2019. Coronary calcium detection using 3D attention identical\ndual deep network based on weakly supervised learning. In: Proceedings of the\nMedical Imaging Image Processing.\n\nItoh, H., Lu, Z., Mori, Y., Misawa, M., Oda, M., Kudo, S.E., Mori, K., 2020. Visual-\nising decision-reasoning regions in computer-aided pathological pattern diag-\nnosis of endoscytoscopic images based on CNN weights analysis. In: HK, H.,\nMA, M. (Eds.), Medical Imaging 2020: Computer-Aided Diagnosis. SPIE, Graduate\nSchool of Informatics, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, Aichi,\n464-8601, Japan doi:10.1117/12.2549532.\n\nJamaludin, A., Kadir, T., Zisserman, A., 2017. SpineNet: automated classification and\nevidence visualization in spinal MRIs. Med. Image Anal. 41, 63-73.\n\nJang, Y., Son, J., Park, K.H., Park, S.J., Jung, K.H., 2018. Laterality classification of fun-\ndus images using interpretable deep neural network. J. Digit. Imaging 31, 923-\n928. doi:10.1007/s10278-018-0099-2.\n\nJetley, S., Lord, N.A., Lee, N., Torr, P., 2018. Learn to Pay Attention. Proceeding of the\nInternational Conference on Learning Representations.\n\nJi, J. 2019. Gradient-based Interpretation on Convolutional Neural Network for Clas-\nsification of Pathological Images. In: Proceeding of the International Confer-\nence on Information Technology and Computer Application, ITCA, pp. 83-86.\ndoi: 10.1109/ITCA49981.2019.00026 Institute of Electrical and Electronics Engi-\nneers Inc., No.2 High School of East China Normal University, Shanghai, China.\n\nJia, X., Ren, L., Cai, J., 2020. Clinical implementation of AI technologies will require\ninterpretable AI models. Med. Phys. 47, 1-4. doi:10.1002/mp.13891.\n\nJiang, H., Yang, K., Gao, M., Zhang, D., Ma, H., Qian, W., 2019. An Interpretable En-\nsemble Deep Learning Model for Diabetic Retinopathy Disease Classification. In:\nProceeding of the 41st Annual International Conference of the IEEE Engineer-\ning in Medicine and Biology Society, EMBC, pp. 2045-2048. doi:10.1109/EMBC.\n2019.8857160 2019. Institute of Electrical and Electronics Engineers Inc., Beijing\nZhizhen Internet Technology Co., Ltd, China.\n"
                },
                {
                    "idx": 2,
                    "thing": "list",
                    "score": 56.77,
                    "box": [
                        1273.4,
                        239.9,
                        2327.6,
                        3031.4
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_17/region_2_list.png",
                    "text": "Jing, B., Xie, P., Xing, E., 2018. On the Automatic Generation of Medical Imaging Re-\nports. In: Proceedings of the 56th Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers), pp. 2577-2586.\n\nKashyap, S., Karargyris, A., Wu, J., Gur, Y., Sharma, A., Wong, K.C.L., Moradi, M.,\nSyeda-Mahmood, T., 2020. Looking in the right place for anomalies: explainable\nAi through automatic location learning. In: Proceeding of the 17th IEEE Inter-\nnational Symposium on Biomedical Imaging, ISBI. I, pp. 1125-1129. doi:10.1109/\nISBI45749.2020.9098370 EEE Computer Society, IBM Research Almaden.\n\nKermany, D.S., Goldbaum, M., Cai, W., Valentim, C.C.S., Liang, H., Baxter, S.L., McK-\neown, A., Yang, G., Wu, X., Yan, F, Dong, J., Prasadha, M.K., Pei, J., Ting, M.,\nZhu, J., Li, C., Hewett, S., Dong, J., Ziyar, I, Shi, A., Zhang, R., Zheng, L., Hou, R.,\nShi, W., Fu, X., Duan, Y., Huu, V.A.N., Wen, C., Zhang, E.D., Zhang, C.L., Li, O.,\nWang, X., Singer, M.A., Sun, X., Xu, J., Tafreshi, A., Lewis, M.A., Xia, H., Zhang, K.,\n2018. Identifying medical diagnoses and treatable diseases by image-based deep\nlearning. Cell 172, 1122-1131. doi:10.1016/j.cell.2018.02.010, e9.\n\nKhakzar, A., Albarqouni, S., Navab, N., 2019. Learning interpretable features via ad-\nversarially robust optimization. Proceeding of the 22nd International Conference\non Medical Image Computing and Computer-Assisted Intervention MICCAI 2019\ndoi: 10.1007 /978-3-030-32226-7_88.\n\nKiani, A., Uyumazturk, B., Rajpurkar, P., Wang, A., Gao, R., Jones, E., Yu, Y., Lan-\nglotz, C.P., Ball, R.L, Montine, TJ., et al., 2020. Impact of a deep learning as-\nsistant on the histopathologic classification of liver cancer. NP] Digit. Med. 3,\n1-8.\n\nKim, B.H., Ye, J.C., 2020. Understanding graph isomorphism network for rs-fMRI\nfunctional connectivity analysis. Front. Neurosci. 14, 630.\n\nKim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F, Sayres, R., 2018. In-\nterpretability beyond feature attribution: quantitative testing with concept ac-\ntivation vectors (TCAV). In: Proceeding of the 35th International Conference on\nMachine Learning, ICML 2018. International Machine Learning Society (IMLS),\npp. 4186-4195.\n\nKim, C., Kim, W.H., Kim, HJ., Kim, J., 2020. Weakly-supervised US breast tumor char-\nacterization and localization with a box convolution network. Proceeding of the\nMedical Imaging: Computer-Aided Diagnosis.\n\nKim, I., Rajaraman, S., Antani, S., 2019. Visual interpretation of convolutional neural\nnetwork predictions in classifying medical image modalities. Diagnostics 9, 38.\n\nKim, M., Han, J.C., Hyun, S.H., Janssens, O., Van Hoecke, S., Kee, C., De Neve, W.,\n2019. Medinoid: computer-aided diagnosis and localization of glaucoma using\ndeep learning. Appl. Sci. 9, 3064.\n\nKim, S.T., Lee, J.H., Ro, Y.M., K, M., HK, H., 2019a. Visual evidence for interpreting di-\nagnostic decision of deep neural network in computer-aided diagnosis. Proceed-\ning of the Medical Imaging: Computer-Aided Diagnosis SPIE, School of Electrical\nEngineering, KAIST, Daejeon, 34141, South Korea doi:10.1117/12.2512621.\n\nKim, Y., Choi, D., Lee, KJ., Kang, Y., Ahn, J.M., Lee, E., Lee, J.W., Kang, H.S., 2020.\nRuling out rotator cuff tear in shoulder radiograph series using deep learning:\nredefining the role of conventional radiograph. Eur. Radiol. 30, 2843-2852.\n\nKim, Y., Lee, K.J., Sunwoo, L., Choi, D., Nam, C.M., Cho, J., Kim, J., Bae, YJ., Yoo, R.E.,\nChoi, B.S., et al., 2019b. Deep learning in diagnosis of maxillary sinusitis using\nconventional radiography. Invest. Radiol. 54, 7-15.\n\nKo, H., Chung, H., Kang, W.S., Kim, K.W., Shin, Y. Kang, SJ., Lee, J.H., Kim, YJ.,\nKim, N.Y., Jung, H., et al., 2020. COVID-19 pneumonia diagnosis using a simple\n2D deep learning framework with a single chest CT image: model development\nand validation. J. Med. Internet Res. 22, e19569.\n\nKoitka, S., Kim, M.S., Qu, M., Fischer, A., Friedrich, C.M., Nensa, F., 2020. Mimick-\ning the radiologists’ workflow: estimating pediatric hand bone age with stacked\ndeep neural networks. Med. Image Anal. 64. doi:10.1016/j.media.2020.101743.\n\nKorbar, B., Olofson, A.M., Miraflor, A.P., Nicka, C.M., Suriawinata, M.A., Torresani, L.,\nSuriawinata, A.A., Hassanpour, S., 2017. Looking under the hood: deep neural\nnetwork visualization to interpret whole-slide image analysis outcomes for col-\norectal polyps. In: Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition Workshops, pp. 69-75.\n\nKowsari, K., Sali, R., Ehsan, L. Adorno, W., Ali, A., Moore, S., Amadi, B., Kelly, P.,\nSyed, S., Brown, D., 2020. HMIC: hierarchical medical image classification, a\ndeep learning approach. Information 11. doi:10.3390/INFO11060318.\n\nKubach, J., Muhlebner-Fahrngruber, A., Soylemezoglu, F., Miyata, H., Niehusmann, P.,\nHonavar, M., Rogerio, F, Kim, S.H., Aronica, E., Garbelli, R., Vilz, S., Popp, A.,\nWalcher, S., Neuner, C., Scholz, M., Kuerten, S., Schropp, V., Roeder, S., Eich-\nhorn, P., Eckstein, M., Brehmer, A., Kobow, K., Coras, R., Blumcke, I., Jabari, S.,\n2020. Same same but different: A Web-based deep learning application revealed\nclassifying features for the histopathologic distinction of cortical malformations.\nEpilepsia 61, 421-432. doi:10.1111/epi.16447.\n\nKumar, D., Sankar, V., Clausi, D., Taylor, G.W., Wong, A., 2019a. SISC: end-to-end in-\nterpretable discovery radiomics-driven lung cancer prediction via stacked inter-\npretable sequencing cells. IEEE Access 7, 145444-145454. doi:10.1109/ACCESS.\n2019.2945524.\n\nKumar, D., Taylor, G.W., Wong, A., 2019b. Discovery radiomics with CLEAR-DR: in-\nterpretable computer aided diagnosis of diabetic retinopathy. IEEE Access 7,\n25891-25896. doi: 10.1109/ACCESS.2019.2893635.\n\nLaLonde, R., Torigian, D., Bagci, U., 2020. Encoding visual attributes in capsules for\nexplainable medical diagnoses. In: Proceedings of the International Conference\non Medical Image Computing and Computer-Assisted Intervention, pp. 294-\n304.\n\nLangner, T., Wikstrém, J., Bjerner, T., Ahlstrém, H., Kullberg, J., 2019. Identifying mor-\nphological indicators of aging with neural networks on large-scale whole-body\nMRI. IEEE Trans. Med. Imaging 39, 1430-1437.\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_18.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_18.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 2,
                "page_idx": 18
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 60.02,
                    "box": [
                        153.9,
                        251.2,
                        1207.4,
                        3117.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_18/region_1_text.png",
                    "text": "Lee, o., KIM, 9.1., KO, YIVL, 2UlSa. Generauion Of Multimodal JuStiNncation using Vi-\nsual word constraint model for explainable computer-aided diagnosis. In: Pro-\nceedings of the 2nd International Workshop on Interpretability of Machine In-\ntelligence in Medical Image Computing, iMIMIC 2019, and the 9th Interna-\ntional Workshop on Multimodal Learning for Clinical Decision Support, ML-\nCDS 2019, held in conjunction with the 22nd International Conference on Med-\nical Imaging and Computer-Assisted Intervention, MICCAI 2019 doi:10.1007/\n978-3-030-33850-3_3, held conjunction with 22nd Interna.\n\nLee, H., Yune, S., Mansouri, M., Kim, M., Tajmir, S.H., Guerrier, CE., Ebert, S.A.,\nPomerantz, S.R., Romero, J.M., Kamalian, S., Gonzalez, R.G., Lev, M.H., Do, S.,\n2019b. An explainable deep-learning algorithm for the detection of acute in-\ntracranial haemorrhage from small datasets. Nat. Biomed. Eng. 3, 173-182.\ndoi:10.1038/s41551-018-0324-9.\n\nLee, J., Nishikawa, R.M., 2019. Detecting mammographically occult cancer in women\nwith dense breasts using deep convolutional neural network and radon cumu-\nlative distribution transform. J. Med. Imaging 6, 44502.\n\nLee, Jeong Hoon, Ha, EJ., Kim, D., Jung, Y.J., Heo, S., Jang, Y.H., An, S.H., Lee, K., 2020.\nApplication of deep learning to the diagnosis of cervical lymph node metastasis\nfrom thyroid cancer with CT: external validation and clinical utility for resident\ntraining. Eur. Radiol. 3066-3072.\n\nLee, Jeong Hyun, Joo, I., Kang, T.W., Paik, Y.H., Sinn, D.H., Ha, S.Y., Kim, K., Choi, C.,\nLee, G., Yi, J., et al., 2020. Deep learning with ultrasonography: automated classi-\nfication of liver fibrosis using a deep convolutional neural network. Eur. Radiol.\n30, 1264-1273.\n\nLei, Y., Tian, Y., Shan, H., Zhang, J.. Wang, G., Kalra, M.K., 2020. Shape and\nmargin-aware lung nodule classification in low-dose CT images via soft acti-\nvation mapping. Med. Image Anal. 60, 101628.\n\nLenis, D., Major, D., Wimmer, M., Berg, A., Sluiter, G., Biihler, K., 2020. Domain aware\nmedical image classifier interpretation by counterfactual impact analysis. In:\nProceedings of the International Conference on Medical Image Computing and\nComputer-Assisted Intervention, pp. 315-325.\n\nLi, C.Y., Liang, X., Hu, Z., Xing, E.P., 2019. Knowledge-driven encode, retrieve, para-\nphrase for medical image report generation. In: Proceedings of the AAAI Con-\nference on Artificial Intelligence, pp. 6666-6673.\n\nLi, L., Xu, M., Liu, H., Li, Y., Wang, X., Jiang, L., Wang, Z., Fan, X., Wang, N., 2019a. A\nlarge-scale database and a CNN model for attention-based glaucoma detection.\nIEEE Trans. Med. Imaging 39, 413-424.\n\nLi, M., Kuang, K., Zhu, Q., Chen, X., Guo, Q., Wu, F, 2020. IB-M: A Flexible Frame-\nwork to Align an Interpretable Model and a Black-box Model. In: Proceedings\nof the IEEE International Conference on Bioinformatics and Biomedicine (BIBM),\npp. 643-649.\n\nLi, Q., Xing, X., Sun, Y., Xiao, B., Wei, H., Huo, Q., Zhang, M., Zhou, X.S., Zhan, Y.,\nXue, Z., et al., 2019b. Novel iterative attention focusing strategy for joint pathol-\nogy localization and prediction of MCI progression. In: Proceedings of the Inter-\nnational Conference on Medical Image Computing and Computer-Assisted Inter-\nvention, pp. 307-315.\n\nLi, W., Zhuang, J., Wang, R., Zhang, J., Zheng, W.S., 2020. Fusing metadata and der-\nmoscopy images for skin disease diagnosis. In: Proceedings of the IEEE 17th\nInternational Symposium on Biomedical Imaging (ISBI), pp. 1996-2000.\n\nLi, X., Wu, J., Chen, E.Z., Jiang, H., 2019c. From deep learning towards finding skin le-\nsion biomarkers. In: Proceedings of the 41st Annual International Conference of\nthe IEEE Engineering in Medicine and Biology Society (EMBC), pp. 2797-2800.\n\nLi, Y., Shafipour, R., Mateos, G., Zhang, Z., 2019d. Mapping brain structural con-\nnectivities to functional networks via graph encoder-decoder with interpretable\nlatent embeddings. In: Proceedings of the 7th IEEE Global Conference on Sig-\nnal and Information Processing, GlobalSIP. Rochester, United States doi:10.1109/\nGlobalSIP45357.2019.8969239, 2019. Institute of Electrical and Electronics Engi-\nneers Inc., University of Rochester, Dept. of Electrical and Computer Engineering.\n\nLi, Z., Wang, C., Han, M., Xue, Y. Wei, W., Li, LJ., Fei-Fei, L. 2019d. Thoracic dis-\nease identification and localization with limited supervision. Adv. Comput. Vis.\nPattern Recognit. doi: 10.1007/978-3-030-13969-8_7.\n\nLian, C., Liu, M., Wang, L., Shen, D., 2019. End-to-end dementia status prediction\nfrom brain mri using multi-task weakly-supervised attention network. In: Pro-\nceedings of the International Conference on Medical Image Computing and\nComputer-Assisted Intervention, pp. 158-167.\n\nLiao, L., Zhang, X., Zhao, F., Lou, J., Wang, L., Xu, X., Zhang, H., Li, G., 2020. Multi-\n-branch deformable convolutional neural network with label distribution learn-\ning for fetal brain age prediction. In: Proceedings of the IEEE 17th International\nSymposium on Biomedical Imaging (ISBI), pp. 424-427.\n\nLiao, W., Zou, B., Zhao, R., Chen, Y., He, Z., Zhou, M., 2019. Clinical interpretable\ndeep learning model for glaucoma diagnosis. IEEE J. Biomed. Health Informat.\ndoi:10.1109/jbhi.2019.2949075.\n\nLin, C.Y., 2004. Rouge: A package for automatic evaluation of summaries. Text sum-\nmarization branches out, pp. 74-81.\n\nLin, Z., Li, S., Ni, D., Liao, Y., Wen, H., Du, J., Chen, S., Wang, T., Lei, B., 2019. Mul-\nti-task learning for quality assessment of fetal head ultrasound images. Med.\nImage Anal. 58, 101548.\n\nLitjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F, Ghafoorian, M., van der\nLaak, J.A.W.M., van Ginneken, B., Sanchez, C.l., 2017. A survey on deep learning\nin medical image analysis. Med. Image Anal. doi:10.1016/j.media.2017.07.005.\n\nLiu, C., Han, X., Li, Z., Ha, J., Peng, G., Meng, W., He, M., 2019. A self-adaptive deep\nlearning method for automated eye laterality detection based on color fundus\nphotography. PLoS One 14. doi:10.1371/journal.pone.0222025.\n\nLiu, H., Wang, L., Nan, Y., Jin, F, Wang, Q., Pu, J., 2019f. SDFN: Segmentation-based\ndeep fusion network for thoracic disease classification in chest X-ray images.\nComput. Med. Imaging Graph. 75, 66-73.\n"
                },
                {
                    "idx": 2,
                    "thing": "list",
                    "score": 59.36,
                    "box": [
                        1275.3,
                        238.1,
                        2327.4,
                        3065.0
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_18/region_2_list.png",
                    "text": "Lundberg, S.M., Lee, S.I., 2017. A unified approach to interpreting model predictions.\nIn: Proceedings of the Advances in Neural Information Processing Systems.\nLuo, L., Chen, H., Wang, X., Dou, Q., Lin, H., Zhou, J., Li, G., Heng, P.A., 2019. Deep\nangular embedding and feature correlation attention for breast MRI cancer anal-\nysis. In: Proceedings of the International Conference on Medical Image Comput-\n\ning and Computer-Assisted Intervention, pp. 504-512.\n\nMa, K., Wu, K., Cheng, H., Gu, C., Xu, R., Guan, X., 2018. A pathology image diag-\nnosis network with visual interpretability and structured diagnostic report. Pro-\nceedings of the 25th International Conference on Neural Information Processing\nICONIP 2018 doi: 10.1007/978-3-030-04224-0_24.\n\nMahmud, T., Rahman, M.A., Fattah, S.A., 2020. CovXNet: A multi-dilation convolu-\ntional neural network for automatic COVID-19 and other pneumonia detection\nfrom chest X-ray images with transferable multi-receptive feature optimization.\nComput. Biol. Med. 122, 103869.\n\nMaicas, G., Bradley, A.P., Nascimento, J.C., Reid, I, Carneiro, G., 2019. Pre and\npost-hoc diagnosis and interpretation of malignancy from breast DCE-MRI. Med.\nImage Anal. 58, 101562.\n\nMaksoud, S., Wiliem, A., Zhao, K., Zhang, T., Wu, L., Lovell, B., 2019. CORAL8: concur-\nrent object regression for area localization in medical image panels. In: Proceed-\nings of the 22nd International Conference Medical Image Computing and Com-\nputer Assisted Intervention MICCAI 2019 doi: 10.1007/978-3-030-32239-7_48.\n\nMalhi, A., Kampik, T., Pannu, H., Madhikermi, M., Framling, K., 2019. Explaining ma-\nchine learning-based classifications of in-vivo gastral images. In: Proceedings of\nthe International Conference on Digital Image Computing: Techniques and Ap-\nplications, DICTA doi: 10.1109/DICTA47822.2019.8945986, 2019. Institute of Elec-\ntrical and Electronics Engineers Inc., Department of Computer Science, Aalto\nUniversity Finland, Finland.\n\nMartins, J., Cardoso, J.S., Soares, F., 2020. Offline computer-aided diagnosis for Glau-\ncoma detection using fundus images targeted at mobile devices. Comput. Meth-\nods Programs Biomed. 192. doi:10.1016/j.cmpb.2020.105341.\n\nMatsui, Y., Maruyama, T., Nitta, M., Saito, T., Tsuzuki, S., Tamura, M., Kusuda, K.,\nFukuya, Y., Asano, H., Kawamata, T., Masamune, K., Muragaki, Y., 2020. Predic-\ntion of lower-grade glioma molecular subtypes using deep learning. J. Neuroon-\ncol. 146, 321-327. doi:10.1007/s11060-019-03376-9.\n\nMeijering, E., 2020. A bird’s-eye view of deep learning in bioimage analysis. Comput.\nStruct. Biotechnol. J. doi:10.1016/j.csbj.2020.08.003.\n\nMeng, Q. Hashimoto, Y., Satoh, S., 2020. How to extract more information\nwith less burden: Fundus image classification and retinal disease localization\nwith ophthalmologist intervention. IEEE J. Biomed. Health Inform. 24, 3351-\n3361.\n\nMeng, Q., Sinclair, M., Zimmer, V., Hou, B., Rajchl, M., Toussaint, N., Oktay, O.,\nSchlemper, J., Gomez, A., Housden, J., et al., 2019. Weakly supervised estima-\ntion of shadow confidence maps in fetal ultrasound imaging. IEEE Trans. Med.\nImaging 38, 2755-2767.\n\nMurdoch, WJ., Singh, C., Kumbier, K., Abbasi-Asl, R., Yu, B., 2019. Definitions, meth-\nods, and applications in interpretable machine learning. Proc. Natl. Acad. Sci.\nUSA 116, 22071-22080. doi:10.1073/pnas.1900654116.\n\nNarayanan, B.N., Hardie, R.C., De Silva, M.S., Kueterman, N.K., 2020. Hybrid machine\nlearning architecture for automated detection and grading of retinal images for\ndiabetic retinopathy. J. Med. Imaging 7, 34501.\n\nNatekar, P., Kori, A., Krishnamurthi, G., 2020. Demystifying brain tumor segmenta-\ntion networks: interpretability and uncertainty analysis. Front. Comput. Neu-\nrosci. 14. doi:10.3389/fncom.2020.00006.\n\nNg, H.G., Kerzel, M., Mehnert, J., May, A., Wermter, S., 2018. Classification of MRI\nmigraine medical data using 3D convolutional neural network. In: Proceedings\nof the International Conference on Artificial Neural Networks, pp. 300-309.\n\nNunes, N., Martins, B., André da Silva, N., Leite, F., J Silva, M., 2019. A multi-\nmodal deep learning method for classifying chest radiology exams. In: Pro-\nceedings of the Conference on Artificial Intelligence EPIA 2019 doi:10.1007/\n978-3-030-30241-2_28.\n\nObikane, S., Aoki, Y., 2020. Weakly Supervised domain adaptation with point super-\nvision in histopathological image segmentation. In: Proceedings of the 5th Asian\nConference on Pattern Recognition, ACPR 2019, pp. 127-140.\n\nOlah, C., Mordvintsev, A., Schubert, L., 2017. Feature visualization. Distill 2, e7.\n\nOlden, J.D., Joy, M.K., Death, R.G., 2004. An accurate comparison of methods for\nquantifying variable importance in artificial neural networks using simulated\ndata. Ecol. Modell. 178, 389-397. doi: 10.1016/j.ecolmodel.2004.03.013.\n\nPapanastasopoulos, Z., Samala, R.K., Chan, H.P, Hadjiiski, L, Paramagul, C.,\nHelvie, M.A., Neal, C.H., 2020. Explainable AI for medical imaging: Deep-learning\nCNN ensemble for classification of estrogen receptor status from breast MRI. In:\nHK, H., MA, M. (Eds.), Medical Imaging 2020: Computer-Aided Diagnosis. SPIE.\nUniversity of Michigan, 1500 E. Medical Center Drive, Ann Arbor, MI 48109-\n5842, United States doi:10.1117/12.2549298.\n\nPapineni, K., Roukos, S., Ward, T., Zhu, WJ., 2002. BLEU: a method for automatic\nevaluation of machine translation. In: Proceedings of the 40th Annual Meeting\nof the Association for Computational Linguistics, pp. 311-318.\n\nPatra, A., Noble, J.A., 2020. Incremental Learning of Fetal Heart Anatomies Using In-\nterpretable Saliency Maps. In: Proceedings of the 23rd Conference Medical Im-\nage Underst. Anal. MIUA 2019 doi:10.1007/978-3-030-39343-4_11.\n\nPaul, H.Y., Kim, T.K., Alice, C.Y., Bennett, B., Eng, J., Lin, C.T., 2020. Can AI outperform\na junior resident? Comparison of deep neural network to first-year radiology\nresidents for identification of pneumothorax. Emerg. Radiol. 27, 367-375.\n\nPaul, H.Y., Kim, T.K., Wei, J., Shin, J., Hui, EK., Sair, H.I., Hager, G.D., Fritz, J., 2019. Au-\ntomated semantic labeling of pediatric musculoskeletal radiographs using deep\nlearning. Pediatr. Radiol. 49, 1066-1070.\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_19.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_19.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 2,
                "page_idx": 19
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 54.5,
                    "box": [
                        147.7,
                        243.2,
                        1206.7,
                        3089.6
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_19/region_1_text.png",
                    "text": "Paul, R., Schabath, M., Gillies, R., Hall, L. Goldgof, D., 2020. Convolutional neural\nnetwork ensembles for accurate lung nodule malignancy prediction 2 years in\nthe future. Comput. Biol. Med. 122, 103882.\n\nPearl, J., 2009. Causality. Cambridge University Press.\n\nPelka, O., Nensa, F,, Friedrich, C.M., 2019. Variations on branding with text occur-\nrence for optimized body parts classification. In: Proceedings of the 2019 41st\nAnnual International Conference of the IEEE Engineering in Medicine and Biol-\nogy Society (EMBC), pp. 890-894.\n\nPeng, T., Boxberg, M., Weichert, W., Navab, N., Marr, C., 2019. Multi-task learn-\ning of a deep K-nearest neighbour network for histopathological image clas-\nsification and retrieval. In: Proceedings of the 22nd International Conference\non Medical Image Computing and Computer-Assisted Intervention MICCAI 2019\ndoi:10.1007/978-3-030-32239-7_75.\n\nPennington, J., Socher, R., Manning, C.D., 2014. Glove: global vectors for word rep-\nresentation. In: Proceedings of the 2014 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pp. 1532-1543.\n\nPerdomo, O., Rios, H., Rodriguez, FJ., Otalora, S. Meriaudeau, F, Miiller, H.,\nGonzalez, F.A., 2019. Classification of diabetes-related retinal diseases using a\ndeep learning approach in optical coherence tomography. Comput. Methods\nPrograms Biomed. 178, 181-189. doi:10.1016/j.cmpb.2019.06.016.\n\nPereira, S., Meier, R., Alves, V., Reyes, M., Silva, C.A., 2018. Automatic brain tumor\ngrading from MRI data using convolutional neural networks and quality assess-\nment. In: Understanding and Interpreting Machine Learning in Medical Image\nComputing Applications. Springer, pp. 106-114.\n\nPesce, E., Joseph Withey, S., Ypsilantis, P.P., Bakewell, R., Goh, V., Montana, G., 2019.\nLearning to detect chest radiographs containing pulmonary lesions using visual\nattention networks. Med. Image Anal. 53, 26-38. doi:10.1016/j.media.2018.12.\n007.\n\nPhilbrick, K.A., Yoshida, K., Inoue, D., Akkus, Z., Kline, T.L., Weston, A.D., Korfiatis, P.,\nTakahashi, N., Erickson, BJ., 2018. What does deep learning see? Insights from\na classifier trained to predict contrast enhancement phase from CT images. Am.\nJ. Roentgenol. 211, 1184-1193. doi:10.2214/AJR.18.20331.\n\nPominova, M., Artemov, A., Sharaev, M., Kondrateva, E., Bernstein, A., Burnaev, E.,\n2018. Voxelwise 3d convolutional and recurrent neural networks for epilepsy\nand depression diagnostics from structural and functional MRI data. In: Pro-\nceedings of the 2018 IEEE International Conference on Data Mining Workshops\n(ICDMW), pp. 299-307.\n\nQi, X., Zhang, L., Chen, Yao, Pi, Y., Chen, Yi, Lv, Q., Yi, Z., 2019. Automated diagnosis\nof breast ultrasonography images using deep neural networks. Med. Image Anal.\n52, 185-198.\n\nQin, R., Wang, Z., Jiang, L., Qiao, K., Hai, J., Chen, J., Xu, J., Shi, D., Yan, B., 2020.\nFine-grained lung cancer classification from PET and CT images based on mul-\ntidimensional attention mechanism. Complexity 2020.\n\nQuellec, G., Lamard, M., Conze, P.H., Massin, P., Cochener, B., 2020. Automatic detec-\ntion of rare pathologies in fundus photographs using few-shot learning. Med.\nImage Anal. 61, 101660.\n\nRadiological Society of North America, 2018. Pneumonia detection challenge.\nhttps://www.rsna.org/education/ai-resources-and-training/ai-image-challenge/\nrsna-pneumonia-detection-challenge-2018\n\nRajaraman, S., Candemir, S., Thoma, G., Antani, S., 2019. Visualizing and explain-\ning deep learning predictions for pneumonia detection in pediatric chest radio-\ngraphs. Med. Imaging 2019. Comput. Aided Diagn., 109500S.\n\nRajpurkar, P., Irvin, J., Ball, R.L, Zhu, K., Yang, B., Mehta, H., Duan, T., Ding, D.,\nBagul, A., Langlotz, C.P., et al., 2018. Deep learning for chest radiograph diag-\nnosis: a retrospective comparison of the CheXNexXt algorithm to practicing ra-\ndiologists. PLoS Med. 15, e1002686.\n\nRajpurkar, P., O’Connell, C., Schechter, A. Asnani, N., Li, J., Kiani, A. Ball, RL,\nMendelson, M., Maartens, G., van Hoving, DJ.others, 2020a. CheXaid: deep\nlearning assistance for physician diagnosis of tuberculosis using chest x-rays in\npatients with HIV. NP] Digit. Med. 3, 1-8.\n\nRajpurkar, P., Park, A., Irvin, J., Chute, C., Bereket, M., Mastrodicasa, D., Langlotz, C.P.,\nLungren, M.P., Ng, A.Y., Patel, B.N., 2020b. AppendiXNet: deep learning for diag-\nnosis of appendicitis from a small dataset of CT exams using video pretraining.\nSci. Rep. 10, 1-7.\n\nReyes, M., Meier, R., Pereira, S., Silva, C.A., Dahlweid, F.M., Tengg-Kobligk, H.V., Sum-\nmers, R.M., Wiest, R., 2020. On the interpretability of artificial intelligence in\nradiology: challenges and opportunities. Radiol. Artif. Intell. 2, e190043.\n\nRezaei, M., Uemura, T., Nappi, J., Yoshida, H., Lippert, C., Meinel, C., 2020. Genera-\ntive synthetic adversarial network for internal bias correction and handling class\nimbalance problem in medical image diagnosis. Medical Imaging 2020. Comput.\nAided Diagn., 113140E.\n\nRibeiro, M.T., Singh, S., Guestrin, C., 2016. Why should i trust you?” Explaining the\npredictions of any classifier. In: Proceedings of the ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining. Association for Comput-\ning Machinery, New York, New York, USA, pp. 1135-1144. doi:10.1145/2939672.\n2939778.\n\nRobnik-Sikonja, M., Kononenko, I., 2008. Explaining classifications for individual\ninstances. IEEE Trans. Knowl. Data Eng. 20, 589-600. doi:10.1109/TKDE.2007.\n190734.\n\nRodin, 1., Fedulova, I., Shelmanov, A., Dylov, D.V, 2019. Multitask and multi-\nmodal neural network model for interpretable analysis of X-ray images. In:\nProceedings of the 019 IEEE International Conference on Bioinformatics and\nBiomedicine (BIBM), pp. 1601-1604.\n\nRonneberger, O., Fischer, P. Brox, T., 2015. U-net: Convolutional networks for\nbiomedical image segmentation. In: Lecture Notes in Computer Science (Includ-\n"
                },
                {
                    "idx": 2,
                    "thing": "list",
                    "score": 60.86,
                    "box": [
                        1275.4,
                        241.1,
                        2329.2,
                        3111.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_19/region_2_list.png",
                    "text": "ing Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioin-\nformatics). Springer Verlag, pp. 234-241. doi:10.1007/978-3-319-24574-4_28.\n\nRudin, C., 2019. Stop explaining black box machine learning models for high stakes\ndecisions and use interpretable models instead. Nat. Mach. Intell. 1, 206-215.\ndoi: 10.1038 /s42256-019-0048-x.\n\nSaab, K., Dunnmon, J., Goldman, R., Ratner, A., Sagreiya, H., Ré, C., Rubin, D., 2019.\nDoubly weak supervision of deep learning models for head CT. In: Proceedings\nof the 22nd Int. Medical Image Computing and Computer Assisted Intervention\nMICCAI 2019 doi:10.1007/978-3-030-32248-9_90.\n\nSabour, S., Frosst, N., Hinton, G.E., 2017. Dynamic routing between capsules. Ad-\nvances in neural information processing systems, p. 30.\n\nSarhan, M.H., Eslami, A., Navab, N., Albarqouni, S., 2019. Learning interpretable dis-\nentangled representations using adversarial VAEs. In: Proceedings of the 1st\nMICCAI Domain Adaptation and Representation Transfer and Medical Image\nLearning with Less Labels and Imperfect Data doi:10.1007/978-3-030-33391-1_\n5, 1st Int. Work. Med. Image Learn. with Less Labels Imperfect Data, MIL3ID\n2019, held conjunction with 22nd Int. Conf. Med..\n\nSchlemper, J., Oktay, O., Schaap, M., Heinrich, M., Kainz, B., Glocker, B., Rueckert, D.,\n2019. Attention gated networks: learning to leverage salient regions in medical\nimages. Med. Image Anal. 53, 197-207. doi:10.1016/j.media.2019.01.012.\n\nSchwab, E., Goossen, A., Deshpande, H., Saalbach, A., 2020. Localization of critical\nfindings in chest X-ray without local annotations using multi-instance learning.\nIn: Proceedings of the 17th IEEE International Symposium on Biomedical Imag-\ning, ISBI 2020. IEEE Computer Society, Clinical Informatics, Solutions Services,\nPhilips Research North America, Cambridge, MA, United States, pp. 1879-1882.\ndoi: 10.1109/ISBI45749.2020.9098551.\n\nSedai, S., Mahapatra, D., Ge, Z., Chakravorty, R., Garnavi, R., 2018. Deep multi-\nscale convolutional feature learning for weakly supervised localization of chest\npathologies in x-ray images. In: International Workshop on Machine Learning\nin Medical Imaging. Springer, Cham, pp. 267-275.\n\nSelvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., 2017.\nGrad-cam: Visual explanations from deep networks via gradient-based localiza-\ntion. In: Proceedings of the IEEE international conference on computer vision,\npp. 618-626.\n\nSeo, D., Oh, K., Oh, I.S., 2020. In: Regional Multi-Scale Approach for Visually Pleasing\nExplanations of Deep Neural Networks, 8. IEEE Access, pp. 8572-8582. doi:10.\n1109/ACCESS.2019.2963055.\n\nShahamat, H., Saniee Abadeh, M., 2020. Brain MRI analysis using a deep learning\nbased evolutionary approach. Neural Netw. 126, 218-234. doi:10.1016/j.neunet.\n2020.03.017.\n\nShapira, N., Fokuhl, J., Schulthei&, M., Beck, S., Kopp, E.K., Pfeiffer, D., Dangelmaier, J.,\nPahn, G., Sauter, A.P., Renger, B., et al., 2020. Liver lesion localisation and classifi-\ncation with convolutional neural networks: a comparison between conventional\nand spectral computed tomography. Biomed. Phys. Eng. Express 6, 15038.\n\nShapley, L.S., 2016. A value for n-person games. In: Contributions to the Theory of\nGames (AM-28), Volume II, 17. Princeton University Press, pp. 307-318. doi:10.\n1515/9781400881970-018.\n\nShen, D., Wu, G., Suk, H.I., 2017. Deep learning in medical image analysis. Annu. Rev.\nBiomed. Eng. 19, 221-248. doi:10.1146/annurev-bioeng-071516-044442.\n\nShen, S., Han, S.X., Aberle, D.R., Bui, A.A., Hsu, W., 2019. An interpretable deep hi-\nerarchical semantic convolutional neural network for lung nodule malignancy\nclassification. Expert Syst. Appl. 128, 84-95. doi:10.1016/j.eswa.2019.01.048.\n\nShen, Y., Sheng, B., Fang, R., Li, H., Dai, L., Stolte, S., Qin, J., Jia, W., Shen, D., 2020.\nDomain-invariant interpretable fundus image quality assessment. Med. Image\nAnal. 61. doi:10.1016/j.media.2020.101654.\n\nShinde, S., Chougule, T., Saini, J., Ingalhalikar, M., 2019a. HR-CAM: Precise localiza-\ntion of pathology using multi-level learning in CNNS. In: Proceedings of the\n22nd International Conference on Medical Image Computing and Computer-\nAssisted Intervention ; MICCAI 2019 doi:10.1007/978-3-030-32251-9_33.\n\nShinde, S., Prasad, S., Saboo, Y., Kaushick, R., Saini, J., Pal, P.K., Ingalhalikar, M., 2019b.\nPredictive markers for Parkinson’s disease using deep neural nets on neurome-\nlanin sensitive MRI. Neurolmage Clin. 22, 101748.\n\nSilva-Rodriguez, J., Colomer, A., Sales, M.A., Molina, R., Naranjo, V., 2020. Going\ndeeper through the Gleason scoring scale: an automatic end-to-end system for\nhistology prostate grading and cribriform pattern detection. Comput. Methods\nPrograms Biomed. 195, 105637.\n\nSilva, W., Fernandes, K., Cardoso, M,J., Cardoso, J.S., 2018. Towards complemen-\ntary explanations using deep neural networks. In: Understanding and Inter-\npreting Machine Learning in Medical Image Computing Applications. Springer,\npp. 133-140.\n\nSilva, W., Poellinger, A., Cardoso, J.S., Reyes, M., 2020. Interpretability-guided con-\ntent-based medical image retrieval. In: Proceedings of the International Con-\nference on Medical Image Computing and Computer-Assisted Intervention,\npp. 305-314.\n\nSimonyan, K., Vedaldi, A., Zisserman, A., 2013. Deep inside convolutional networks:\nvisualising image classification models and saliency maps. In: Proceedings of\nthe 2nd International Conference on Learning Representations ICLR 2014 -\nWorkshop Track Proceedings.\n\nSimonyan, K., Zisserman, A., 2014. Very deep convolutional networks for large-scale\nimage recognition. In: Proceedings of the International Conference on Learning\nRepresentations, pp. 1-14.\n\nSingh, S., Karimi, S., Ho-Shon, K., Hamey, L., 2019. From chest X-rays to radiology\nreports: a multimodal machine learning approach. 2019 International Confer-\nence on Digital Image Computing: Techniques and Applications, DICTA 2019. In-\nstitute of Electrical and Electronics Engineers Inc., Department of Computing,\nMacquarie University, Sydney, Australia doi:10.1109/DICTA47822.2019.89458 19.\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_20.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_20.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 2,
                "page_idx": 20
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "text",
                    "score": 52.73,
                    "box": [
                        148.8,
                        242.1,
                        1206.0,
                        3094.2
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_20/region_1_text.png",
                    "text": "Singla, S., Gong, M., Ravanbakhsh, S., Sciurba, F., Poczos, B., Batmanghelich, K.N.,\n2018. Subject2Vec: generative-discriminative approach from a set of im-\nage patches to a vector. 21st International Conference on Medical Image\nComputing and Computer-Assisted Intervention MICCAI 2018 doi:10.1007/\n978-3-030-00928-1_57.\n\nSociety for Imaging Informatics in Medicine, American College of Radiology, 2019.\nPneumothorax segmentation [WWW Document] URL.\n\nSonderby, C.K., Raiko, T., Maalge, L., Sonderby, S.K., Winther, O., 2016. Ladder vari-\national autoencoders, in: Lee, D.D., Sugiyama, M., Luxburg, U. V, Guyon, I., Gar-\nnett, R. (Eds.), Advances in Neural Information Processing Systems 29. Curran\nAssociates, Inc., pp. 3738-3746.\n\nSpinks, G., Moens, M.F, 2019. Justifying diagnosis decisions by deep neural net-\nworks. J. Biomed. Inform. 96. doi:10.1016/j.jbi.2019.103248.\n\nSpringenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., 2014. Striving for sim-\nplicity: the all convolutional net. In: Proceedings of the 3rd International Con-\nference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9,\n2015, Conference Track Proceedings.\n\nSun, H., Zeng, X., Xu, T., Peng, G., Ma, Y., 2020. Computer-Aided Diagnosis in\nHistopathological Images of the Endometrium Using a Convolutional Neural\nNetwork and Attention Mechanisms. IEEE J. Biomed. Health Inform. 24, 1664-\n1676. doi:10.1109/JBHI.2019.2944977.\n\nSun, L. Wang, W., Li, J., Lin, J., 2019. Study on medical image report generation\nbased on improved encoding-decoding method. In: Proceedings of the Interna-\ntional Conference on Intelligent Computing, pp. 686-696.\n\nTang, C., 2020. Discovering Unknown Diseases with Explainable Automated Medical\nImaging. In: Proceedings of the Annual Conference on Medical Image Under-\nstanding and Analysis, pp. 346-358.\n\nTang, R., Tushar, F.I., Han, S., Hou, R., Rubin, G.D., Lo, J.Y., 2019. Classification of chest\nCT using case-level weak supervision. Medical Imaging 2019: Computer-Aided\nDiagnosis, 1095017.\n\nTang, Y.X., Tang, Y.B., Peng, Y., Yan, K., Bagheri, M., Redd, B.A., Brandon, CJ., Lu, Z.,\nHan, M., Xiao, J., et al., 2020. Automated abnormality classification of chest ra-\ndiographs using deep convolutional neural networks. NPJ Digit. Med. 3, 1-8.\n\nTang, Z. Chuang, K.V, DeCarli, C., Jin, LW., Beckett, L, Keiser, MJ., Dug-\nger, B.N., 2019. Interpretable classification of Alzheimer’s disease pathologies\nwith a convolutional neural network pipeline. Nat. Commun. 10. doi:10.1038/\ns41467-019-10212-1.\n\nTeramoto, A., Yamada, A., Kiriyama, Y., Tsukamoto, T., Yan, K., Zhang, L., Imaizumi, K.,\nSaito, K., Fujita, H., 2019. Automated classification of benign and malignant cells\nfrom lung cytological images using deep convolutional neural network. Inform.\nMed. Unlocked 16, 100205.\n\nThakoor, K.A., Li, X., Tsamis, E., Sajda, P., Hood, D.C., 2019. Enhancing the accuracy\nof glaucoma detection from OCT probability maps using convolutional neural\nnetworks. In: Proceedings of the 2019 41st Annual International Conference\nof the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 2036-\n2040.\n\nTian, J., Li, C., Shi, Z., Xu, F., 2018. A diagnostic report generator from CT volumes on\nliver tumor with semi-supervised attention mechanism. Proceedings of the 21st\nInternational Conference on Medical Image Computing and Computer-Assisted\nIntervention MICCAI 2018 doi:10.1007/978-3-030-00934-2_78.\n\nTian, J., Zhong, C., Shi, Z., Xu, F, 2019. Towards automatic diagnosis from multi-\nmodal medical data. In: Interpretability of Machine Intelligence in Medical Im-\nage Computing and Multimodal Learning for Clinical Decision Support. Springer,\npp. 67-74.\n\nTibshirani, R., 1996. Regression shrinkage and selection via the lasso. J. R. Stat. Soc.\n58, 267-288.\n\nTsang, M., Cheng, D., Liu, Y., 2018. Detecting statistical interactions from neural net-\nwork weights. In: Proceedings of the International Conference on Learning Rep-\nresentations.\n\nTu, Z., Gao, S., Zhou, K., Chen, X., Fu, H., Gu, Z., Cheng, J., Yu, Z., Liu, J.. 2020. SUNet:\na lesion regularized model for simultaneous diabetic retinopathy and diabetic\nmacular edema grading. In: Proceedings of the 2020 IEEE 17th International\nSymposium on Biomedical Imaging (ISBI), pp. 1378-1382.\n\nUehara, K., Murakawa, M., Nosato, H., Sakanashi, H., 2019. Prototype-based inter-\npretation of pathological image analysis by convolutional neural networks. In:\nProceedings of the Asian Conference on Pattern Recognition, pp. 640-652.\n\nUpadhyay, U., Banerjee, B., 2020. Compact representation learning using class spe-\ncific convolution coders-application to medical image classification. In: Proceed-\nings of the 020 IEEE 17th International Symposium on Biomedical Imaging\n(ISBI), pp. 1266-1270.\n\nUzunova, H., Ehrhardt, J., Kepp, T., Handels, H., 2019. Interpretable explanations of\nblack box classifiers applied on medical images by meaningful perturbations\nusing variational autoencoders. In: Medical Imaging 2019: Image Processing,\n10949. SPIE, pp. 264-271.\n\nvan Amsterdam, W.A.C., Verhoeff, J.J.C., de Jong, P.A., Leiner, T., Eijkemans, MJ.C.,\n2019. Eliminating biasing signals in lung cancer images for progno-\nsis predictions with deep learning. npj Digit. Med. 2, 1-6. doi:10.1038/\ns41746-019-0194-x.\n\nvan de Schoot, R., de Bruin, J., Schram, R., Zahedi, P., de Boer, J., Weijdema, F,\nKramer, B., Huijts, M., Hoogerwerf, M., Ferdinands, G., et al., 2021. An open\nsource machine learning framework for efficient and transparent systematic re-\nviews. Nat. Mach. Intell. 3, 125-133.\n\nvan der Velden, B.H.M., Janse, M.H.A., Ragusi, M.A.A., Loo, C.E., Gilhuijs, K.G.A., 2020.\nVolumetric breast density estimation on MRI using explainable deep learning\nregression. Sci. Rep. 10. doi:10.1038/s41598-020-75167-6.\n"
                },
                {
                    "idx": 2,
                    "thing": "text",
                    "score": 54.14,
                    "box": [
                        1273.1,
                        244.6,
                        2328.5,
                        3065.1
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_20/region_2_text.png",
                    "text": "van Sloun, RJ.G., Demi, L., 2019. Localizing B-lines in lung ultrasonography by\nweakly supervised deep learning, in-vivo results. IEEE J. Biomed. Heal. Inform.\n24, 957-964.\n\nVedantam, R., Lawrence Zitnick, C., Parikh, D., 2015. Cider: consensus-based image\ndescription evaluation. In: Proceedings of the IEEE Conference on Computer Vi-\nsion and Pattern Recognition, pp. 4566-4575.\n\nVila-Blanco, N., Carreira, M.J., Varas-Quintana, P., Balsa-Castro, C., Tomas, I., 2020.\nDeep neural networks for chronological age estimation from OPG images. IEEE\nTrans. Med. Imaging 39, 2374-2384.\n\nVinyals, O., Toshev, A., Bengio, S., Erhan, D., 2015. Show and tell: a neural image\ncaption generator. In: Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition, pp. 3156-3164.\n\nvon Schacky, C.E., Sohn, J.H., Liu, F, Ozhinsky, E., Jungmann, P.M., Nardo, L.,\nPosadzy, M., Foreman, S.C., Nevitt, M.C., Link, T.M., et al., 2020. Development\nand validation of a multitask deep learning model for severity grading of hip\nosteoarthritis features on radiographs. Radiology 295, 136-145.\n\nWang, CJ., Hamm, C.A., Savic, LJ., Ferrante, M., Schobert, I., Schlachter, T., Lin, M.D.,\nWeinreb, J.C., Duncan, J.S., Chapiro, J., Letzen, B. 2019. Deep learning for\nliver tumor diagnosis part II: convolutional neural network interpretation\nusing radiologic imaging features. Eur. Radiol. 29, 3348-3357. doi:10.1007/\ns00330-019-06214-8.\n\nWang, H., Feng, J., Zhang, Z., Su, H., Cui, L, He, H., Liu, L., 2018. Breast mass classifi-\ncation via deeply integrating the contextual information from multi-view data.\nPattern Recognit 80, 42-52. doi:10.1016/j.patcog.2018.02.026.\n\nWang, J., Cui, Y., Shi, G., Zhao, J., Yang, X., Qiang, Y., Du, Q., Ma, Y., Kazihise, N.G.F,\n2020. Multi-branch cross attention model for prediction of KRAS mutation in\nrectal cancer with t2-weighted MRI. Appl. Intell. 50, 2352-2369.\n\nWang, J., Zhang, R., Wei, X., Li, X., Yu, M., Zhu, J., Gao, J., Liu, Z., Yu, R., 2019. An\nattention-based semi-supervised neural network for thyroid nodules segmenta-\ntion. In: Proceedings of the 2019 IEEE International Conference on Bioinformat-\nics and Biomedicine (BIBM), pp. 871-876.\n\nWang, K., Zhang, X., Huang, S., 2019. KGZNet: Knowledge-guided deep zoom\nneural networks for thoracic disease classification. In: Proceedings of the\n2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),\npp. 1396-1401.\n\nWang, L., Zhang, L., Zhu, M., Qi, X., Yi, Z., 2020. Automatic diagnosis for thyroid\nnodules in ultrasound images by deep neural networks. Med. Image Anal. 61,\n101665.\n\nWang, R., Fan, D., Lv, B., Wang, M., Zhou, Q., Lv, C., Xie, G., Wang, L., 2020a. OCT\nimage quality evaluation based on deep and shallow features fusion network.\nIn: Proceedings of the 2020 IEEE 17th International Symposium on Biomedical\nImaging (ISBI), pp. 1561-1564.\n\nWang, S., Xing, Y., Zhang, L., Gao, H., Zhang, H., 2019a. Deep convolutional neural\nnetwork for ulcer recognition in wireless capsule endoscopy: experimental fea-\nsibility and optimization. Comput. Math. Methods Med. 2019.\n\nWang, Xi, Chen, H., Ran, A.R., Luo, L, Chan, PP, Tham, CC., Chang, R.T., Man-\nnil, S.S., Cheung, C.Y., Heng, P.A., 2020b. Towards multi-center glaucoma OCT\nimage screening with semi-supervised joint structure and function multi-task\nlearning. Med. Image Anal. 63, 101695.\n\nWang, X, Liang, X., Jiang, Z., Nguchu, B.A., Zhou, Y., Wang, Y., Wang, H., Li, Y., Zhu, Y.,\nWu, F., Gao, J.H., Qiu, B., 2020c. Decoding and mapping task states of the hu-\nman brain via deep learning. Hum. Brain Mapp 41, 1505-1519. doi:10.1002/hbm.\n24891.\n\nWang, X., Peng, Y., Lu, L., Lu, Z., Summers, R.M., 2018. TieNet: text-image embed-\nding network for common thorax disease classification and reporting in chest\nX-rays. In: Proceedings of the 31st Meeting of the IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition, CVPR 2018. IEEE Computer Society, United\nStates, pp. 9049-9058. doi:10.1109/CVPR.2018.00943 Department of Radiology\nand Imaging Sciences, Clinical Center.\n\nWang, X., Xu, M., Li, L., Wang, Z., Guan, Z., 2019b. Pathology-aware deep network vi-\nsualization and its application in glaucoma image synthesis. In: Proceedings of\nthe International Conference on Medical Image Computing and Computer-As-\nsisted Intervention, pp. 423-431.\n\nWang, X, Zhang, Y., Guo, Z., Li, J., 2019c. A computational framework towards\nmedical image explanation. In: Proceedings of the 7th Joint International\nWorkshop on Knowledge Representation for Health Care Process doi:10.1007/\n978-3-030-37446-4_10, Inf. Syst. Heal. Care, KR4HC/ProHealth 2019 1st Work.\nTransparent, Explain. Affect. Al Med. Syst. TEAAM 2019 held conjuncti.\n\nKoh, P.W., Liang, P., 2017. Understanding black-box predictions via influence func-\ntions. In: International conference on machine learning. PMLR, pp. 1885-1894.\n\nWei, W., Poirion, E. Bodini, B., Durrleman, S., Ayache, N., Stankoff, B., Col-\nliot, O., 2019. Predicting PET-derived demyelination from multimodal MRI using\nsketcher-refiner adversarial training for multiple sclerosis. Med. Image Anal. 58,\n101546.\n\nWickstrom, K., Kampffmeyer, M., Jenssen, R., 2020. Uncertainty and interpretabil-\nity in convolutional neural networks for semantic segmentation of colorectal\npolyps. Med. Image Anal. 60, 101619.\n\nWindisch, P., Weber, P., Fiirweger, C., Ehret, F., Kufeld, M., Zwahlen, D., Muacevic, A.,\n2020. Implementation of model explainability for a basic brain tumor detection\nusing convolutional neural networks on MRI slices. Neuroradiology doi:10.1007/\ns00234-020-02465-1.\n\nWoerl, A.C., Eckstein, M., Geiger, J., Wagner, D.C., Daher, T., Stenzel, P., Fernandez, A.,\nHartmann, A., Wand, M., Roth, W., et al., 2020. Deep learning predicts molecular\nsubtype of muscle-invasive bladder cancer from conventional histopathological\nslides. Eur. Urol. 78, 256-264.\n"
                }
            ]
        },
        {
            "page": {
                "original_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages/page_21.png",
                "current_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/pages_ordered/page_21.png",
                "image_width": 2481,
                "image_height": 3308,
                "regions_num": 2,
                "page_idx": 21
            },
            "regions": [
                {
                    "idx": 1,
                    "thing": "list",
                    "score": 68.96,
                    "box": [
                        154.2,
                        240.7,
                        1206.4,
                        2642.8
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_21/region_1_list.png",
                    "text": "Wu, B., Zhou, Z., Wang, J., Wang, Y., 2018. Joint learning for pulmonary nodule seg-\nmentation, attributes and malignancy prediction. In: Proceedings of the 15th\nIEEE International Symposium on Biomedical Imaging, ISBI 2018. IEEE Computer\nSociety, China, pp. 1109-1113. doi:10.1109/ISBI.2018.8363765 Nat'l Engineering\nLaboratory for Video Technology Cooperative Medianet Innovation Center, Key\nLaboratory of Machine Perception (MoE) Sch’l of EECS, Peking University, Bei-\njing, 100871.\n\nXi, P., Guan, H., Shu, C., Borgeat, L., Goubran, R., 2019. An integrated approach for\nmedical abnormality detection using deep patch convolutional neural networks.\nVis. Comput. 1-14.\n\nXie, B., Lei, T., Wang, N., Cai, H., Xian, J., He, M., Zhang, L., Xie, H., 2020. Comput-\ner-aided diagnosis for fetal brain ultrasound images using deep convolutional\nneural networks. Int. J. Comput. Assist. Radiol. Surg. 15, 1303-1312.\n\nXie, Y., Zhang, J., Xia, Y., Shen, C., 2020. A mutual bootstrapping model for auto-\nmated skin lesion segmentation and classification. IEEE Trans. Med. Imaging 39,\n2482-2493.\n\nXu, H., Dong, M., Lee, M.H., O’Hara, N., Asano, E., Jeong, J.W., 2019. Objective detec-\ntion of eloquent axonal pathways to minimize postoperative deficits in pediatric\nepilepsy surgery using diffusion tractography and convolutional neural net-\nworks. IEEE Trans. Med. Imaging 38, 1910-1922. doi:10.1109/TMI.2019.2902073.\n\nXu, R, Cong, Z., Ye, X., Hirano, Y., Kido, S., Gyobu, T., Kawata, Y., Honda, O.,\nTomiyama, N., 2019. Pulmonary textures classification via a multi-scale atten-\ntion network. IEEE J. Biomed. Heal. Inform. 24, 2041-2052.\n\nYan, C., Xu, J., Xie, J., Cai, C., Lu, H., 2020. Prior-Aware CNN with multi-task learn-\ning for colon images analysis. In: Proceedings of the 17th IEEE International\nSymposium on Biomedical Imaging, ISBI 2020. IEEE Computer Society, Nan-\njing University of Information Science Technology, Nanjing, China, pp. 254-257.\ndoi:10.1109/ISBI45749.2020.9098703.\n\nYan, K., Peng, Y., Sandfort, V., Bagheri, M., Lu, Z., Summers, R.M., 2019. Holistic and\ncomprehensive annotation of clinically significant findings on diverse CT im-\nages: Learning from radiology reports and label ontology. In: Proceedings of\nthe 32nd JEEE/CVF Conference on Computer Vision and Pattern Recognition,\nCVPR 2019. IEEE Computer Society, United States, pp. 8515-8524. doi:10.1109/\nCVPR.2019.00872 Imaging Biomarkers and Computer-Aided Diagnosis Labora-\ntory, Clinical Center, National Institutes of Health, Bethesda, MD 20892.\n\nYan, K., Wang, X., Lu, L, Zhang, L., Harrison, A.P., Bagheri, M., Summers, R.M.,\n2018. Deep lesion graphs in the wild: relationship learning and organization\nof significant radiology image findings in a diverse large-scale lesion database.\nIn: Proceedings of the 31st Meeting of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition, CVPR 2018. IEEE Computer Society, United\nStates, pp. 9261-9270. doi:10.1109/CVPR.2018.00965 Imaging Biomarkers and\nComputer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Cen-\nter, 10 Center Drive, Bethesda, MD 20892.\n\nYan, Y., Kawahara, J., Hamarneh, G., 2019. Melanoma Recognition via Visual Atten-\ntion. In: Proceedings of the 26th International Conference on Information Pro-\ncessing in Medical Imaging, IPMI 2019 doi:10.1007/978-3-030-20351-1_62.\n\nYang, H., Kim, J-Y., Kim, H., Adhikari, S.P., 2019. Guided soft attention network for\nclassification of breast cancer histopathology images. IEEE Trans. Med. Imaging\n39, 1306-1315.\n\nYang, P., Zhai, Y., Li, L., Lv, H., Wang, J., Zhu, C., Jiang, R., 2020. A deep metric learning\napproach for histopathological image retrieval. Methods 179, 14-25.\n\nYang, S., Niu, J., Wu, J., Liu, X., 2020. Automatic medical image report generation\nwith multi-view and multi-modal attention mechanism. In: Proceedings of the\nInternational Conference on Algorithms and Architectures for Parallel Process-\ning, pp. 687-699.\n\nYang, X., Wang, Z., Liu, C., Le, H.M., Chen, J., Cheng, K.T.T., Wang, L. 2017. Joint\ndetection and diagnosis of prostate cancer in multi-parametric MRI based on\nmultimodal convolutional neural networks. In: Proceedings of the International\nConference on Medical Image Computing and Computer-Assisted Intervention,\npp. 426-434.\n\nYe, H., Gao, F., Yin, Y., Guo, D., Zhao, P., Lu, Y., Wang, X., Bai, J., Cao, K., Song, Q.,\net al., 2019. Precise diagnosis of intracranial hemorrhage and subtypes using a\nthree-dimensional joint convolutional and recurrent neural network. Eur. Radiol.\n29, 6191-6201.\n\nYi, P.H., Lin, A., Wei, J., Yu, A.C. Sair, H.I, Hui, F.K., Hager, G.D., Harvey, S.C., 2019.\nDeep-learning-based semantic labeling for 2D mammography and comparison\nof complexity for machine learning tasks. J. Digit. Imaging 32, 565-570. doi:10.\n1007/s10278-019-00244-w.\n\nYin, C., Qian, B., Wei, J., Li, X., Zhang, X., Li, Y., Zheng, Q., 2019. Automatic gener-\nation of medical imaging diagnostic report with hierarchical recurrent neural\nnetwork. In: Proceedings of the IEEE International Conference on Data Mining\n(ICDM), pp. 728-737.\n"
                },
                {
                    "idx": 2,
                    "thing": "list",
                    "score": 58.77,
                    "box": [
                        1274.1,
                        240.6,
                        2327.7,
                        2619.9
                    ],
                    "crop_image_path": "/mnt/sh_flex_storage/home/zehanyu/repos/GPT-Paper/pdfs/cancer_review/Med Image Anal. 2022 Explainable artificial intelligence (XAI) in deep learning-based medical image analysis/crops_ordered/page_21/region_2_list.png",
                    "text": "Young, K., Booth, G., Simpson, B., Dutton, R., Shrapnel, S., 2019. Deep neural network\nor dermatologist? In: Proceedings of the 2nd International Workshop on Inter-\npretability of Machine Intelligence in Medical Image Computing, IMIMIC 2019\ndoi: 10.1007/978-3-030-33850-3_6, 9th Int. Work. Multimodal Learn. Clin. De-\ncis. Support. ML-CDS 2019, held conjunction with 22nd Interna.\n\nYuan, J., Liao, H., Luo, R., Luo, J., 2019. Automatic radiology report generation based\non multi-view image fusion and medical concept enrichment. In: Proceedings\nof the International Conference on Medical Image Computing and Computer-As-\nsisted Intervention, pp. 721-729.\n\nZeiler, M.D., Fergus, R., 2014. Visualizing and understanding convolutional net-\nworks. In: Lecture Notes in Computer Science. Springer Verlag, pp. 818-833.\ndoi: 10.1007/978-3-319-10590-1_53 (Including subseries lecture notes in artifi-\ncial intelligence and lecture notes in bioinformatics).\n\nZeng, X., Wen, L., Xu, Y., Ji, C., 2020. Generating diagnostic report for medical image\nby high-middle-level visual information incorporation on double deep learning\nmodels. Comput. Methods Progr. Biomed. 197, 105700.\n\nZhang, B., Tan, J., Cho, K., Chang, G., Deniz, C.M., 2020. Attention-based cnn for\nkl grade classification: data from the osteoarthritis initiative. In: Proceed-\nings of the IEEE 17th International Symposium on Biomedical Imaging (ISBI),\npp. 731-735.\n\nZhang, R., Tan, S., Wang, R., Manivannan, S., Chen, J., Lin, H., Zheng, W.S., 2019.\nBiomarker localization by combining CNN classifier and generative adversarial\nnetwork. In: Proceedings of the 22nd International Conference on Medical Im-\nage Computing and Computer-Assisted Intervention. MICCAI 2019 doi:10.1007/\n978-3-030-32239-7_24.\n\nZhang, Y., Ding, D.Y., Qian, T., Manning, C.D., Langlotz, C.P., 2018. Learning to sum-\nmarize radiology findings. In: Proceedings of the Ninth International Workshop\non Health Text Mining and Information Analysis. Association for Computational\nLinguistics, Brussels, Belgium, pp. 204-213. doi:10.18653/v1/W18-5623.\n\nZhang, Z., Chen, P, Sapkota, M., Yang, L, 2017a. TandemNet: distilling knowl-\nedge from medical images using diagnostic reports as optional semantic ref-\nerences. Proceedings of the 20th International Conference on Medical Im-\nage Computing and Computer-Assisted Intervention. MICCAI 2017 doi:10.1007/\n978-3-319-66179-7_37.\n\nZhang, Z., Xie, Y., Xing, F, McGough, M., Yang, L., 2017b. MDNet: a semantically\nand visually interpretable medical image diagnosis network. In: Proceedings of\nthe30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR\n2017. Institute of Electrical and Electronics Engineers Inc., University of Florida,\nUnited States, pp. 3549-3557. doi:10.1109/CVPR.2017.378.\n\nZhao, C., Han, J., Jia, Y., Fan, L., Gou, F., 2018. Versatile framework for medical im-\nage processing and analysis with application to automatic bone age assessment.\nJournal of Electrical and Computer Engineering 2018.\n\nZhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., 2016. Learning deep fea-\ntures for discriminative localization. In: Proceedings of the IEEE conference on\ncomputer vision and pattern recognition, pp. 2921-2929.\n\nZhou, K., Gao, S., Cheng, J., Gu, Z., Fu, H., Tu, Z., Yang, J., Zhao, Y., Liu, J., 2020.\nSparse-gan: Sparsity-constrained generative adversarial network for anomaly\ndetection in retinal oct image. In: Proceedings of the IEEE 17th International\nSymposium on Biomedical Imaging (ISBI), pp. 1227-1231.\n\nZhou, L.Q., Wu, X.L., Huang, S.Y., Wu, G.G., Ye, H.R., Wei, Q, Bao, LY. Deng, Y.B.,\nLi, X.R., Cui, X.W., et al., 2020. Lymph node metastasis prediction from primary\nbreast cancer US images using deep learning. Radiology 294, 19-28.\n\nZhu, P., Ogino, M., 2019. Guideline-based additive explanation for computer-aided\ndiagnosis of lung nodules. In: Proceedings of the 2nd International Workshop\non Interpretability of Machine Intelligence in Medical Image Computing, IMIMIC\n2019 doi:10.1007/978-3-030-33850-3_5, 9th Int. Work. Multimodal Learn. Clin.\nDecis. Support. ML-CDS 2019, held conjunction with 22nd Interna.\n\nZhu, Z., Albadawy, E., Saha, A., Zhang, J., Harowicz, M.R., Mazurowski, M.A., 2019.\nDeep learning for identifying radiogenomic associations in breast cancer. Com-\nput. Biol. Med. 109, 85-90. doi:10.1016/j.compbiomed.2019.04.018.\n\nZhu, Z., Ding, X., Zhang, D., Wang, L., 2020. Weakly-supervised balanced attention\nnetwork for gastric pathology image localization and classification. In: Proceed-\nings of the IEEE 17th International Symposium on Biomedical Imaging (ISBI),\npp. 1-4.\n\nZintgraf, L.M., Cohen, T.S., Adel, T., Welling, M., 2017. Visualizing deep neural net-\nwork decisions: prediction difference analysis. In: Proceedings of the 5th In-\nternational Conference on Learning Representations, ICLR 2017. University of\nAmsterdam, Netherlands International Conference on Learning Representations,\nICLR.\n\nZunair, H., Hamza, A.B., 2020. Melanoma detection using adversarial training and\ndeep transfer learning. Phys. Med. Biol. 65, 135005.\n"
                }
            ]
        }
    ]
}